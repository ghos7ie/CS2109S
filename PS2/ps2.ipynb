{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2: Local & Adversarial Search\n",
    "\n",
    "**Release Date:** 1 September 2025\n",
    "\n",
    "**Due Date:** 13 September 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In class, we discussed a range of search algorithms. In this problem set, we will get some hands-on practice by implementing local search for the **Travelling Salesman Problem (TSP)**, which operates in a fully-observable, single-agent, deterministic, episodic, static, and discrete environment. We will also get some hands-on practice on Adversarial Search by coding an AI to play the game **Breakthrough**.\n",
    "\n",
    "**Required Files**:\n",
    "* ps2.py\n",
    "\n",
    "**Plagiarism Policy**: Please refer to our [Course Policies](https://canvas.nus.edu.sg/courses/77861/pages/course-policies)\n",
    "\n",
    "**IMPORTANT**: While it is possible to write and run Python code directly in Jupyter notebook, we recommend that you do this Problem set with an IDE using the .py file provided. An IDE will make debugging significantly easier.\n",
    "\n",
    "**Post-Problem Set Survey**:\n",
    "Your feedback is important to us! After completing Problem Set 2, please take a moment to share your thoughts by filling out this [survey](https://coursemology.org/courses/3095/surveys/2714)."
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Travelling Salesman Problem (TSP)\n",
    "\n",
    "Your cousin Ben Bitdiddle is planning to start a company which sells premium imported chocolate from Europe. Among all cities in the country, Ben must choose one to be his company headquarters to receive shipment from Europe and devise a route from the headquarters to deliver the chocolate to every other city. This route must only visit each city **exactly once** and return to the headquarters to receive the next shipment. In addition, to save fuel cost, the route must be **as short as possible**. Given a list of cities and the distance between every two cities, what is the shortest possible route?\n",
    "\n",
    "This problem is a classic NP-hard optimisation problem in computer science. In this task, you will design and implement a local search algorithm to find a shortest route. You must find the route as **a list of cities** in the order of travel from the starting city to the last city before returning.\n",
    "\n",
    "For example, consider the graph below, which represents 4 cities and the distances between them.\n",
    "\n",
    "![image.png](attachment:image-2.png)\n",
    "\n",
    "An optimal route is `[0, 1, 2, 3]`, with the minimal distance travelled of 1 + 2 + 2 + 3 = 8.\n",
    "\n",
    "**Note:**\n",
    "* There can be more than 1 shortest route, e.g., `[1, 0, 3, 2]`, `[1, 3, 2, 0]`, etc. You only need to find one such route.\n",
    "* `[0, 1, 2]` is not legal as the route must go through all 4 cities.\n",
    "* `[0, 1, 2, 3, 1]` is not legal as city 1 is visited more than once.\n",
    "* `[1, 3, 0, 2]` is legal but it is not the shortest route, as the distance travelled of 3 + 3 + 2 + 2 = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: State representation\n",
    "Propose a state representation for this problem if we want to formulate it as a local search problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State representation is of the list of cities visited, in order of visitation.\n",
    "\n",
    "e.g. [1, 0, 3, 2] as mentioned in the context."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Initial and goal states\n",
    "\n",
    "What are the initial and goal states for the problem under your proposed representation?\n",
    "\n",
    "**Note:**\n",
    "* In many optimization problems such as the TSP, the path to the goal is irrelevant; **the goal state itself is the solution to the problem**.\n",
    "* Local search algorithms keep a single \"current\" state and move from a state to another in the search space by applying local changes (with the help of a *successor function*), until an optimal solution is found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial state - random permutation of a route\n",
    "\n",
    "Goal state - route with shortest path to each city before returning to the start (must have n elements, where n is number of cities)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you do better?\n",
    "\n",
    "Recall that similar to A* search, local search utilises evaluation functions to decide how to transition from one state to another. However, being an uninformed guy, your cousin Ben Bitdiddle tells you to use the \"greedy\" solution. Given an incomplete route, the \"greedy\" solution builds a path by adding the closest unvisited node from the last visited node, until all nodes are visited. For instance, in the graph above, the \"greedy\" solution is `[0, 1, 2, 3]`.\n",
    "\n",
    "Although this solution seems relatively sensible, as a CS2109S student, you have a nagging feeling that it may not work all the time. Can you create an evaluation function and successor function to get better results with local search?\n",
    "\n",
    "\n",
    "**Note:**\n",
    "\n",
    "* For the following tasks, we will be benchmarking your hill-climbing algorithm against our own version using the greedy solution. Note that the hidden test cases can be quite large, so any brute-force solution will not suffice. \n",
    "\n",
    "* Your own evaluation functions and successor functions may underperform against the greedy solution for small instances of TSP, but should outperform the greedy solution consistently for large instances. For our public and private test cases, we have designed the greedy solution to be suboptimal.\n",
    "\n",
    "* If your code does not pass the private test cases on Coursemology because it underperforms against the greedy solution, you may re-run your code a few times in case you are \"unlucky\" with random initial routes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3: State transitions\n",
    "\n",
    "Implement a reasonable successor function `successor(route)` to generate new routes by applying minor \"tweaks\" (swap the order of visits) to the current route. It should return a list of new routes to be used in the next iteration in the hill-climbing algorithm.\n",
    "\n",
    "**Note:**\n",
    "* At each iteration, the routes generated from the successor function are evaluated against each other (using an evaluation function). The best route will be selected for the next iteration if it is better than the current route.\n",
    "* Your successor function should not return too many routes as it would take too much time for evaluation. (do not enumerate all possible states otherwise it will timeout, only generate \"neighbors\")\n",
    "* However, if too few routes are generated, you are more likely to be stuck at a local maxima as each route will be compared against fewer routes.\n",
    "* Although the successor function is non-deterministic, you should keep the randomness low. Hence, random shuffling of all cities is not allowed. Your successor function must exploit the quality of the current route.\n",
    "* Private test cases will test the quality of `successor`. If you fail the private test cases and are certain your solution is fine, rerun a few times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following cell before proceeding. You may use any of the imported libraries/classes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this cell before you start!\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from typing import List, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def successor(route: List[int]) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Generates new routes to be used in the next iteration in the hill-climbing algorithm.\n",
    "\n",
    "    Args:\n",
    "        route (List[int]): The current route as a list of cities in the order of travel.\n",
    "\n",
    "    Returns:\n",
    "        new_routes (List[List[int]]): New routes to be considered.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# Test cases\n",
    "def test_successor(route):\n",
    "    sorted_route = sorted(route)\n",
    "    result = successor(route)\n",
    "    assert result is not None, \"Successor function returns an empty list.\"\n",
    "    assert any(result), \"Successor function returns an empty list.\"\n",
    "    for new_route in result:\n",
    "        assert len(new_route) == len(sorted_route), \"New route does not have the same number of cities as the original route.\"\n",
    "        assert sorted(new_route) == sorted_route, \"New route does not contain all cities present in the original route.\"\n",
    "\n",
    "permutation_route = list(range(4))\n",
    "new_permutation_routes = successor(permutation_route)\n",
    "assert len(new_permutation_routes) < 24, \"Your successor function may have generated too many new routes by enumerating all possible states.\"\n",
    "\n",
    "test_successor([1, 3, 2, 0])\n",
    "test_successor([7, 8, 6, 3, 5, 4, 9, 2, 0, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4: Evaluation function\n",
    "Implement an evaluation function `evaluation_func(cities, distances, route)` that would be helpful in deciding on the \"goodness\" of a route, i.e. an optimal route should return a higher evaluation score than a suboptimal one.\n",
    "\n",
    "Please note that the route must only visit each city **exactly once** and **return to the headquarters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_func(\n",
    "    cities: int,\n",
    "    distances: List[Tuple[int]],\n",
    "    route: List[int]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes the evaluation score of a route\n",
    "\n",
    "    Args:\n",
    "        cities (int): The number of cities to be visited.\n",
    "\n",
    "        distances (List[Tuple[int]]): The list of distances between every two cities. Each distance\n",
    "            is represented as a tuple in the form of (c1, c2, d), where c1 and c2 are the two cities\n",
    "            and d is the distance between them. The length of the list should be equal to cities *\n",
    "            (cities - 1)/2.\n",
    "\n",
    "        route (List[int]): The current route as a list of cities in the order of travel.\n",
    "\n",
    "    Returns:\n",
    "        h_n (float): the evaluation score.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# Test cases\n",
    "cities = 4\n",
    "distances = [(1, 0, 10), (0, 3, 22), (2, 1, 8), (2, 3, 30), (1, 3, 25), (0, 2, 15)]\n",
    "\n",
    "\n",
    "route_1 = evaluation_func(cities, distances, [0, 1, 2, 3])\n",
    "route_2 = evaluation_func(cities, distances, [2, 1, 3, 0])\n",
    "route_3 = evaluation_func(cities, distances, [1, 3, 2, 0])\n",
    "route_4 = evaluation_func(cities, distances, [2, 3, 0, 1])\n",
    "\n",
    "assert route_1 == route_2\n",
    "assert route_1 > route_3\n",
    "assert route_1 == route_4, \"Have you considered the cost to travel from the last city to the headquarter (first)?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.5: Explain your evaluation function\n",
    "\n",
    "Explain why your evaluation function is suitable for this problem (how a higher evaluation score indicates that a route is more optimal than the other)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hill-climbing\n",
    "Using the representation above, we can implement the hill-climbing algorithm `hill_climbing(cities, distances, successor, evaluation_func)`, which takes in the number of cities and the list of distances, a successor function, an evaluation function and returns the shortest route as a list of cities.\n",
    "\n",
    "1. The hill-climbing approach is a local search algorithm which starts with a randomly-initialised state and continuously selects the next candidate solution that locally maximizes the reduction of the evaluation function.\n",
    "\n",
    "2. The algorithm terminates when a (local) maxima is reached, i.e. a solution that cannot be improved further by looking at the next candidate solutions.\n",
    "\n",
    "3. Unlike previous search algorithms you have implemented, hill-climbing only keeps a single current state. As such, it does not involve a search tree/graph. Backtracking is also not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climbing(\n",
    "    cities: int,\n",
    "    distances: List[Tuple[int]],\n",
    "    successor: Callable,\n",
    "    evaluation_func: Callable\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Hill climbing finds the solution to reach the goal from the initial.\n",
    "\n",
    "    Args:\n",
    "        cities (int): The number of cities to be visited.\n",
    "\n",
    "        distances (List[Tuple[int]]): The list of distances between every two cities. Each distance\n",
    "            is represented as a tuple in the form of (c1, c2, d), where c1 and c2 are the two cities\n",
    "            and d is the distance between them. The length of the list should be equal to cities *\n",
    "            (cities - 1)/2.\n",
    "\n",
    "        Successor (Callable): A function that generates new routes to be used in the next\n",
    "            iteration in the hill-climbing algorithm. Will be provided on Coursemology.\n",
    "\n",
    "        evaluation_func (Callable): A function that computes the evaluation score of a route. Will\n",
    "            be provided on Coursemology.\n",
    "\n",
    "    Returns:\n",
    "        route (List[int]): The shortest route, represented by a list of cities in the order to be\n",
    "            traversed.\n",
    "    \"\"\"\n",
    "    route = random.sample(list(range(cities)), cities)\n",
    "    curr_hn = evaluation_func(cities, distances, route)\n",
    "    while True:\n",
    "        new_routes = successor(route)\n",
    "        best_new_route = max(new_routes, key=lambda x: evaluation_func(cities, distances, x))\n",
    "        h_n = evaluation_func(cities, distances, best_new_route)\n",
    "        if h_n <= curr_hn:\n",
    "            return route\n",
    "\n",
    "        curr_hn = h_n\n",
    "        route = best_new_route"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.6: Improved hill-climbing\n",
    "\n",
    "When no \"better\" neighbouring solutions are present, local search can be stuck at a local maxima. Think of a way you can combat this limitation, and implement `hill_climbing_improved(cities, distances, successor, evaluation_func, hill_climbing)` below.\n",
    "\n",
    "* Coursemology will test this question with correct implementation of `successor(route)`, `evaluation_func(cities, distances, route)` and `hill_climbing(cities, distances, successor, evaluation_func)`\n",
    "* Note that the implemented `evaluation_func(cities, distances, route)` returns a float, which can be from `float(-inf)` to `float(inf)`.\n",
    "* Note that the `hill_climbing(cities, distances, successor, evaluation_func)` is implemented with random starting states, so there is no need to provide a random starting state manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climbing_improved(\n",
    "    cities: int,\n",
    "    distances: List[Tuple[int]],\n",
    "    successor: Callable,\n",
    "    evaluation_func: Callable,\n",
    "    hill_climbing: Callable\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Improved hill climbing that finds the solution to reach the goal from the initial.\n",
    "\n",
    "    Args:\n",
    "        cities (int): The number of cities to be visited.\n",
    "\n",
    "        distances (List[Tuple[int]]): The list of distances between every two cities. Each distance\n",
    "            is represented as a tuple in the form of (c1, c2, d), where c1 and c2 are the two cities\n",
    "            and d is the distance between them. The length of the list should be equal to cities *\n",
    "            (cities - 1)/2.\n",
    "\n",
    "        successor (Callable): The successor function to be used in hill climbing. Will be\n",
    "            provided on Coursemology.\n",
    "\n",
    "        evaluation_func (Callable): The evaluation function to be used in hill climbing. Will be\n",
    "            provided on Coursemology.\n",
    "\n",
    "        hill_climbing (Callable): The hill climbing function to be used for each restart. Will be\n",
    "            provided on Coursemology.\n",
    "\n",
    "    Returns:\n",
    "        route (List[int]): The shortest route, represented by a list of cities in the order to be\n",
    "            traversed.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# Test cases\n",
    "def test_improved_hill_climbing(cities: int, distances: List[Tuple[int]], successor, evaluation_func, hill_climbing, hill_climbing_improved):\n",
    "    route = hill_climbing_improved(cities, distances, successor, evaluation_func, hill_climbing)\n",
    "    assert sorted(route) == list(range(cities)), \"New route does not contain all cities present in the original route.\"\n",
    "\n",
    "cities_1 = 4\n",
    "distances_1 = [(1, 0, 10), (0, 3, 22), (2, 1, 8), (2, 3, 30), (1, 3, 25), (0, 2, 15)]\n",
    "\n",
    "test_improved_hill_climbing(cities_1, distances_1, successor, evaluation_func, hill_climbing, hill_climbing_improved)\n",
    "\n",
    "cities_2 = 10\n",
    "distances_2 = [(2, 7, 60), (1, 6, 20), (5, 4, 70), (9, 8, 90), (3, 7, 54), (2, 5, 61),\n",
    "    (4, 1, 106), (0, 6, 51), (3, 1, 45), (0, 5, 86), (9, 2, 73), (8, 4, 14), (0, 1, 51),\n",
    "    (9, 7, 22), (3, 2, 22), (8, 1, 120), (5, 7, 92), (5, 6, 60), (6, 2, 10), (8, 3, 78),\n",
    "    (9, 6, 82), (0, 2, 41), (2, 8, 99), (7, 8, 71), (0, 9, 32), (4, 0, 73), (0, 3, 42),\n",
    "    (9, 1, 80), (4, 2, 85), (5, 9, 113), (3, 6, 28), (5, 8, 81), (3, 9, 72), (9, 4, 81),\n",
    "    (5, 3, 45), (7, 4, 60), (6, 8, 106), (0, 8, 85), (4, 6, 92), (7, 6, 70), (7, 0, 22),\n",
    "    (7, 1, 73), (4, 3, 64), (5, 1, 80), (2, 1, 22)]\n",
    "\n",
    "test_improved_hill_climbing(cities_2, distances_2, successor, evaluation_func, hill_climbing, hill_climbing_improved)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.7: Comparison between local search and other search algorithms\n",
    "\n",
    "Compared to previous search algorithms you have seen (uninformed search, A* search), why do you think local search is more suitable for this problem?\n",
    "\n",
    "Recommended points to discuss:\n",
    "* Size of search space\n",
    "* Is there any goal state / goal test to terminate our search algorithm?\n",
    "* What kind of output are we looking for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Search is more suitable because this is an optimisation problem, so the goal can be any state.\n",
    "\n",
    "**Size of search space**\n",
    "\n",
    "Since the size of search space is extremely large, it is not practical to use A*/uninformed search as search through all possible solutions.\n",
    "\n",
    "Local search focuses on improving a singular solution, hence, making it a better choice for this problem.\n",
    "\n",
    "**Is there any goal state/goal state to terminate our search algorithm?**\n",
    "\n",
    "The goal is not a specific state so A*/uninformed search will not know when to terminate due to the lack of a heuristic function. \n",
    "\n",
    "**What kind of output are we looking for?**\n",
    "\n",
    "We are looking for the most optimal solution, which local search is designed to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakthrough\n",
    "\n",
    "Breakthrough was the winner of the 2001 8 × 8 Game Design Competition, sponsored by *About.com* and *Abstract Games Magazine*. When Dan Troyka formulated it, it was originally for a 7×7 board. We’re going to play it on a 6×6 board to limit the complexity. In terms of our terminology for the agent environment, Breakthrough is a fully observable, strategic, deterministic game. The game always results in a win for one of the two players.\n",
    "\n",
    "How exactly do you design an agent to play this game and, most importantly, win? An agent takes sensory input and reasons about it, and then outputs an action at each time step. You thus need to create a program that can read in a representation of the board (that’s the input) and output a legal move in Breakthrough. You then need an evaluation function to evaluate how good a position is.\n",
    "\n",
    "In this problem set, you will first implement a minimax agent, followed by augmenting it with alpha-beta pruning. You will then implement an improved evaluation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakthrough Technical Description\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src=\"images/breakthrough_board.png\">\n",
    "Figure 1. Game Board\n",
    "</p>\n",
    "</pre>\n",
    "\n",
    "*Figure 1* shows the starting position of our game board. The player controlling the black pieces can move the black pawns (**B**), and the other player controlling the white pieces can move the white pawns (**W**). Each player can only move pieces of their own colour during their turn. Black can move its pawns forward towards the bottom of the board, while white can move its pawns forward towards the top of the board. Black wins by moving any piece to the opposite side, row (horizontal) index 5. White wins by moving any piece to row (horizontal) index 0. A side also wins if their opponent has no pieces left. **Kindly follow the same indexing as provided in *Figure 1***.\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src=\"images/game_move_black.png\">\n",
    "Figure 2. Possible Moves for Black\n",
    "</p>\n",
    "</pre>\n",
    "\n",
    "Pieces move one space directly forward or diagonally forward, and only capture diagonally forward. An example of possible moves for black is illustrated in *Figure 2*. In this figure, the black pawn at (3, 2) can move forward to any of the three spaces in row index 4. The black pawn at (0, 4) can either move diagonally right to (1, 5), or capture by moving diagonally left to (1, 3). It cannot capture by moving forward; its forward movement is blocked by the white pawn at (1, 4). Note that your move is not allowed to take your pawn outside the board.\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src=\"images/game_move_white.png\">\n",
    "Figure 3. Possible Moves for White\n",
    "</p>\n",
    "</pre>\n",
    "\n",
    "The same movement rules apply to white as illustrated in *Figure 3*. In this figure, the white pawn at (1, 3) can move forward to any of the three spaces in row index 0. The white pawn at (4, 2) can either move diagonally right to (3, 3), or capture by moving diagonally left to (3, 1). It cannot capture by moving forward; its forward movement is blocked by the black pawn at (3, 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided Utility Functions\n",
    "\n",
    "You can use the function provided as you see fit. The function `Player.get_opponent()` will return the opponent's colour given a player colour. You will implement other functions later on to supplement the given minimax algorithm.\n",
    "\n",
    "- `Player.get_opponent()`: Given a player colour, it returns the opponent's colour.\n",
    "- `print_state(board)`: It takes in the board 2D list as parameter and prints out the current state of the board in a comprehensible way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following cell before proceeding. You may use any of the imported libraries/classes here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this cell before you start!\n",
    "\"\"\"\n",
    "\n",
    "import copy\n",
    "from enum import Enum\n",
    "from typing import Callable, Union\n",
    "\n",
    "class Player(Enum):\n",
    "    BLACK = 'black'\n",
    "    WHITE = 'white'\n",
    "\n",
    "    # returns the opponent of the current player\n",
    "    def get_opponent(self):\n",
    "        if self == Player.BLACK:\n",
    "            return Player.WHITE\n",
    "        else:\n",
    "            return Player.BLACK\n",
    "        \n",
    "# board row and column -> these are constant\n",
    "ROW, COL = 6, 6\n",
    "INF = 90129012\n",
    "WIN = 21092109\n",
    "MOVE_NONE = (-1, -1), (-1, -1)\n",
    "TIME_LIMIT = 10\n",
    "\n",
    "Score = Union[int, float]\n",
    "Move = tuple[tuple[int, int], tuple[int, int]]\n",
    "Board = list[list[str]]\n",
    "State = tuple[Board, Player]\n",
    "Action = tuple[tuple[int, int], tuple[int, int]]\n",
    "\n",
    "\n",
    "# prints out the current state of the board in a comprehensible way\n",
    "def print_state(board: Board) -> None:\n",
    "    horizontal_rule = \"+\" + (\"-\" * 5 + \"+\") * COL\n",
    "    for row in board:\n",
    "        print(horizontal_rule)\n",
    "        print(f\"|  {'  |  '.join(' ' if tile == '_' else tile for tile in row)}  |\")\n",
    "    print(horizontal_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build your own agent, you will need a heuristic function to evaluate a position. The heuristic function below evaluates the board from black's perspective. You will be using this heuristic function for tasks 2.1 and 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(state: State) -> Score:\n",
    "    \"\"\"\n",
    "    Returns the score of the current position.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "    representing black pawn, white pawn, and empty cell, respectively.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An evaluation (as a Score).\n",
    "    \"\"\"\n",
    "    bcount = 0\n",
    "    wcount = 0\n",
    "    board = state[0]\n",
    "    for r, row in enumerate(board):\n",
    "        for tile in row:\n",
    "            if tile == \"B\":\n",
    "                if r == 5:\n",
    "                    return WIN\n",
    "                bcount += 1\n",
    "            elif tile == \"W\":\n",
    "                if r == 0:\n",
    "                    return -WIN\n",
    "                wcount += 1\n",
    "    if wcount == 0:\n",
    "        return WIN\n",
    "    if bcount == 0:\n",
    "        return -WIN\n",
    "    return bcount - wcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided heuristic function returns `WIN` if black wins, and `-WIN` if white wins. Otherwise, it takes the difference between the number of black pieces and the number of white pieces that are on the board. The value of `WIN` can be found and has a value of `21092109`.\n",
    "\n",
    "**Note**: On Coursemology, we will provide and use this heuristic function to test your code in task 2.1 and task 2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax Algorithm\n",
    "\n",
    "Your agent must be able to calculate the game state a few moves in advance, by implementing the **minimax** algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Implementing Breakthrough for Minimax\n",
    "\n",
    "In the lecture, you have seen the minimax algorithm without and with cutoff. Here we have given to you minimax with cutoff, as the depth of the game and the branching factor in certain positions can be (very) large and we do not have the computational power to compute the entire game until the terminal states.\n",
    "\n",
    "The minimax function explores different game states, until either the depth is `max_depth`, or there is a winner. In these cases, the minimax algorithm uses the provided heuristic function, `utility(board)` to evaluate the position.\n",
    "\n",
    "The minimax function is able to handle making the first move for either black or white. Regardless of which player moves first, the minimax evaluation and returned score is always done from the perspective of black.\n",
    "\n",
    "You are to implement the following functions given below:\n",
    "- `valid_actions(state)` to generate all possible moves for a player given the current board state. The function should work for the current player to move, whether it is black or white.\n",
    "- `transition(state, action)`: Given the state and action (source and dest), this function updates the board configuration based on the indicated action. \n",
    "- `is_terminal(state)`: Given the state, it returns `True` if the game is over, `False` otherwise.\n",
    "- `utility(state)`: Returns the score of a terminal state\n",
    "\n",
    "\n",
    "**Note**: \n",
    "* For tasks 2.1 and 2.2, if you are certain that your solution is correct but the test cases fail on Coursemology due to timeout, just rerun your code. Depending on the load on Coursemology, a correct solution might still timeout.\n",
    "* The algorithm returns scores from the black perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_actions(\n",
    "    state: State\n",
    ") -> set[Action]:\n",
    "    \"\"\"\n",
    "    Generates a list containing all possible actions in a particular position for the current player\n",
    "    to move. Return an empty set if there are no possible actions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state: A tuple conntaining board and current_player information. Board is a 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. current_player is the colour of the current player to move.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A set of Actions.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "def transition(\n",
    "        state: State,\n",
    "        action: Action,\n",
    "    ) -> State:\n",
    "    \"\"\"\n",
    "    Updates the board configuration by modifying existing values if in_place is set to True,\n",
    "    or creating a new board with updated values if in_place is set to False.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state: A tuple conntaining board and current_player information. Board is a 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. current_player is the colour of the current player to move.\n",
    "    action: A tuple containing source and destination position of the pawn.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The new State.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# checks if it is a terminal state\n",
    "def is_terminal(state: State) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if game is over.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state: A tuple conntaining board and current_player information. Board is a 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. current_player is the colour of the current player to move.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A bool representing whether the game is over.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "def utility(state: State) -> int:\n",
    "    \"\"\"\n",
    "    Returns score of the terminal state from the point of view of black.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state: A tuple conntaining board and current_player information. Board is a 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. current_player is the colour of the current player to move.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int representing the score.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "\n",
    "def evaluate (state: State) -> int:\n",
    "    \"\"\"\n",
    "    Returns the value of heuristic(state) if it has hit max_depth, otherwise calls utility(state) if it is a terminal state\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state: A tuple conntaining board and current_player information. Board is a 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. current_player is the colour of the current player to move.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int representing the score.\n",
    "    \"\"\"\n",
    "    #It has hit max_depth\n",
    "    if not is_terminal(state):\n",
    "        return heuristic(state)\n",
    "    \n",
    "    return utility(state)\n",
    "\n",
    "\n",
    "def minimax(\n",
    "    board: Board,\n",
    "    depth: int,\n",
    "    max_depth: int,\n",
    "    current_player: Player,\n",
    ") -> tuple[Score, Action]:\n",
    "    \"\"\"\n",
    "    Finds the best move for the current player and corresponding evaluation from black's\n",
    "    perspective for the input board state. Return MOVE_NONE if no move is possible\n",
    "    (e.g. when the game is over).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. Your function may modify\n",
    "        the board internally, but the original board passed as an argument must remain unchanged.\n",
    "\n",
    "    depth: int, the depth to search for the best move. When this is equal to `max_depth`, you\n",
    "        should get the evaluation of the position using the provided heuristic function.\n",
    "\n",
    "    max_depth: int, the maximum depth for cutoff.\n",
    "\n",
    "    current_player: Player, the colour of the current player to move.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple (evaluation, ((src_row, src_col), (dst_row, dst_col))):\n",
    "    evaluation: the best score that the current player to move can achieve.\n",
    "    src_row, src_col: position of the pawn to move.\n",
    "    dst_row, dst_col: position to move the pawn to.\n",
    "    \"\"\"\n",
    "\n",
    "    state = (board,current_player)\n",
    "    \n",
    "    if depth == max_depth or is_terminal(state):\n",
    "        return evaluate(state), MOVE_NONE\n",
    "\n",
    "    if current_player == Player.BLACK:\n",
    "        best_score = -INF\n",
    "    else:\n",
    "        best_score = INF\n",
    "\n",
    "    best_move = MOVE_NONE\n",
    "    next_player = current_player.get_opponent()\n",
    "\n",
    "    for action in valid_actions(state):\n",
    "        child = transition(state, action)\n",
    "        new_board = child[0]\n",
    "        score = minimax(new_board, depth + 1, max_depth, next_player)[0]\n",
    "\n",
    "        if current_player == Player.BLACK:\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_move = action\n",
    "        else:\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_move = action\n",
    "\n",
    "    return best_score, best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "# Test cases for valid_actions\n",
    "def test_valid_actions():\n",
    "    # Test case 1: A single black pawn in the middle with all three forward moves possible\n",
    "    board_1 = [\n",
    "        list(\"______\"),\n",
    "        list(\"__B___\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "    ]\n",
    "    state_1 = (board_1, Player.BLACK)\n",
    "    actions_1 = valid_actions(state_1)\n",
    "    expected_actions_1 = {\n",
    "        ((1, 2), (2, 1)), \n",
    "        ((1, 2), (2, 2)), \n",
    "        ((1, 2), (2, 3))\n",
    "    }\n",
    "    assert actions_1 == expected_actions_1, \"valid_actions failed for a single black pawn with 3 empty forward squares.\"\n",
    "\n",
    "    # Test case 2: A single white pawn at the edge with two forward moves possible\n",
    "    board_2 = [\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"W_____\"),\n",
    "        list(\"______\"),\n",
    "    ]\n",
    "    state_2 = (board_2, Player.WHITE)\n",
    "    actions_2 = valid_actions(state_2)\n",
    "    expected_actions_2 = {\n",
    "        ((4, 0), (3, 0)), \n",
    "        ((4, 0), (3, 1))\n",
    "    }\n",
    "    assert actions_2 == expected_actions_2, \"valid_actions failed for a single white pawn at the edge.\"\n",
    "\n",
    "    # Test case 3: Mixed moves for a black pawn\n",
    "    board_3 = [\n",
    "        list(\"______\"),\n",
    "        list(\"___B__\"),\n",
    "        list(\"__W_W_\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "    ]\n",
    "    state_3 = (board_3, Player.BLACK)\n",
    "    actions_3 = valid_actions(state_3)\n",
    "    expected_actions_3 = {\n",
    "        ((1, 3), (2, 2)),\n",
    "        ((1, 3), (2, 3)),\n",
    "        ((1, 3), (2, 4))\n",
    "    }\n",
    "    assert actions_3 == expected_actions_3, \"valid_actions failed for Black's mixed moves (move and capture).\"\n",
    "\n",
    "    # Test case 4: A fully blocked black pawn has no moves.\n",
    "    board_4 = [\n",
    "        list(\"______\"),\n",
    "        list(\"__B___\"),\n",
    "        list(\"_BWB__\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "    ]\n",
    "    state_4 = (board_4, Player.BLACK)\n",
    "    actions_4 = valid_actions(state_4)\n",
    "    pawn_at_1_2_moves = {action for action in actions_4 if action[0] == (1, 2)}\n",
    "    assert len(pawn_at_1_2_moves) == 0, \"valid_actions failed for a fully blocked pawn; it should have no moves.\"\n",
    "\n",
    "    print(\"All valid_actions tests passed!\")\n",
    "\n",
    "# Test cases for transition\n",
    "def test_transition():\n",
    "    # Test case 1: Black pawn moves forward\n",
    "    board_1 = [\n",
    "        list(\"______\"),\n",
    "        list(\"__B___\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "    ]\n",
    "    state_1 = (board_1, Player.BLACK)\n",
    "    action_1 = ((1, 2), (2, 2))\n",
    "    new_state_1 = transition(state_1, action_1)\n",
    "    expected_board_1 = [\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"__B___\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "    ]\n",
    "    assert new_state_1[0] == expected_board_1, \"transition failed for Black's forward move.\"\n",
    "\n",
    "    # Test case 2: White pawn captures a black pawn\n",
    "    board_2 = [\n",
    "        list(\"______\"),\n",
    "        list(\"__B___\"),\n",
    "        list(\"_W____\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "    ]\n",
    "    state_2 = (board_2, Player.WHITE)\n",
    "    action_2 = ((2, 1), (1, 2))\n",
    "    new_state_2 = transition(state_2, action_2)\n",
    "    expected_board_2 = [\n",
    "        list(\"______\"),\n",
    "        list(\"__W___\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "    ]\n",
    "    assert new_state_2[0] == expected_board_2, \"transition failed for White's capture move.\"\n",
    "    \n",
    "    # Test case 3: Original board is not modified\n",
    "    original_board = [\n",
    "        list(\"______\"),\n",
    "        list(\"__B___\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "        list(\"______\"),\n",
    "    ]\n",
    "    original_board_copy = copy.deepcopy(original_board)\n",
    "    state_3 = (original_board, Player.BLACK)\n",
    "    action_3 = ((1, 2), (2, 2))\n",
    "    transition(state_3, action_3)\n",
    "    assert original_board == original_board_copy, \"transition function should not modify the original board.\"\n",
    "\n",
    "    print(\"All transition tests passed!\")\n",
    "\n",
    "# Test cases for is_terminal\n",
    "def test_is_terminal():\n",
    "    # Test case 1: Black wins by reaching the end\n",
    "    board_1 = [\n",
    "        list(\"______\"), list(\"______\"), list(\"______\"),\n",
    "        list(\"______\"), list(\"______\"), list(\"___B__\"),\n",
    "    ]\n",
    "    assert is_terminal((board_1, Player.BLACK)) is True, \"is_terminal failed for Black's win condition.\"\n",
    "\n",
    "    # Test case 2: White wins by eliminating all black pieces\n",
    "    board_2 = [\n",
    "        list(\"______\"), list(\"__W___\"), list(\"______\"),\n",
    "        list(\"______\"), list(\"______\"), list(\"___W__\"),\n",
    "    ]\n",
    "    assert is_terminal((board_2, Player.WHITE)) is True, \"is_terminal failed when Black has no pieces.\"\n",
    "\n",
    "    # Test case 3: Non-terminal state\n",
    "    board_3 = [\n",
    "        list(\"______\"), \n",
    "        list(\"__B___\"), \n",
    "        list(\"______\"),\n",
    "        list(\"_W____\"), \n",
    "        list(\"______\"), \n",
    "        list(\"______\"),\n",
    "    ]\n",
    "    assert is_terminal((board_3, Player.BLACK)) is False, \"is_terminal failed for a non-terminal state.\"\n",
    "\n",
    "    print(\"All is_terminal tests passed!\")\n",
    "\n",
    "# Test cases for utility\n",
    "def test_utility():\n",
    "    # Test case 1: Black wins\n",
    "    board_1 = [\n",
    "        list(\"______\"), list(\"______\"), list(\"______\"),\n",
    "        list(\"______\"), list(\"______\"), list(\"B_____\"),\n",
    "    ]\n",
    "    assert utility((board_1, Player.BLACK)) == WIN, \"utility failed for Black's win.\"\n",
    "\n",
    "    # Test case 2: White wins\n",
    "    board_2 = [\n",
    "        list(\"W_____\"), list(\"______\"), list(\"______\"),\n",
    "        list(\"______\"), list(\"______\"), list(\"______\"),\n",
    "    ]\n",
    "    assert utility((board_2, Player.WHITE)) == -WIN, \"utility failed for White's win.\"\n",
    "\n",
    "    # Test case 3: Black wins (no white pieces)\n",
    "    board_3 = [\n",
    "        list(\"______\"), list(\"B_____\"), list(\"______\"),\n",
    "        list(\"______\"), list(\"______\"), list(\"______\"),\n",
    "    ]\n",
    "    assert utility((board_3, Player.BLACK)) == WIN, \"utility failed for Black's win by eliminating opponent.\"\n",
    "\n",
    "    print(\"All utility tests passed!\")\n",
    "\n",
    "test_valid_actions()\n",
    "test_transition()\n",
    "test_is_terminal()\n",
    "test_utility()\n",
    "\n",
    "print(\"\\nAll new test cases for core functions passed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha-beta Pruning\n",
    "\n",
    "With minimax, our agent can see the future within a few moves. However, the naive implementation of minimax may explore many redundant states, which slows down our agent. As discussed in the lecture, we can apply **alpha-beta pruning** to eliminate unnecessary states, thereby improving our agent's speed and its ability to see even further into the future. This will increase our agent's strength and its likelihood of winning the game. \n",
    "\n",
    "First, you should try to integrate alpha-beta pruning with the standard minimax algorithm. Similar to Task 2.1, your minimax function with alpha-beta pruning must be able to handle making the first move for either black or white.\n",
    "\n",
    "**Copy over your Task 2.1 implementation** and adapt it into alpha beta pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Integrate alpha-beta pruning into minimax\n",
    "\n",
    "Note: The Coursemology evaluator is set with a time limit, so you might get a timeout error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax_alpha_beta(\n",
    "    board: Board,\n",
    "    depth: int,\n",
    "    max_depth: int,\n",
    "    alpha: Score,\n",
    "    beta: Score,\n",
    "    current_player: Player\n",
    ") -> tuple[Score, Move]:\n",
    "    \"\"\"\n",
    "    Finds the best move for the current player and corresponding evaluation from black's\n",
    "    perspective for the input board state. Return MOVE_NONE if no move is possible\n",
    "    (e.g. when the game is over).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. Your function may modify\n",
    "        the board internally, but the original board passed as an argument must remain unchanged.\n",
    "\n",
    "    depth: int, the depth to search for the best move. When this is equal to `max_depth`, you\n",
    "        should get the evaluation of the position using the provided heuristic function.\n",
    "\n",
    "    max_depth: int, the maximum depth for cutoff.\n",
    "\n",
    "    alpha: Score. The alpha value in a given state.\n",
    "\n",
    "    beta: Score. The beta value in a given state.\n",
    "\n",
    "    current_player: Player, the colour of the current player\n",
    "        to move.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple (evaluation, ((src_row, src_col), (dst_row, dst_col))):\n",
    "    evaluation: the best score that the current player to move can achieve.\n",
    "    src_row, src_col: position of the pawn to move.\n",
    "    dst_row, dst_col: position to move the pawn to.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_41 = [\n",
    "    list(\"______\"),\n",
    "    list(\"__BB__\"),\n",
    "    list(\"____BB\"),\n",
    "    list(\"WBW_B_\"),\n",
    "    list(\"____WW\"),\n",
    "    list(\"_WW___\"),\n",
    "]\n",
    "\n",
    "board_42 = [\n",
    "    list(\"____B_\"),\n",
    "    list(\"__BB__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_WWW__\"),\n",
    "    list(\"____W_\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "board_33 = [\n",
    "    list(\"______\"),\n",
    "    list(\"__B___\"),\n",
    "    list(\"W_____\"),\n",
    "    list(\"___B_B\"),\n",
    "    list(\"__W___\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "board_34 = [\n",
    "    list(\"______\"),\n",
    "    list(\"____BB\"),\n",
    "    list(\"__B___\"),\n",
    "    list(\"_W_B_B\"),\n",
    "    list(\"__W_W_\"),\n",
    "    list(\"___WW_\"),\n",
    "]\n",
    "\n",
    "preservation_board = [\n",
    "    list(\"___B__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_B__B_\"),\n",
    "    list(\"W____W\"),\n",
    "    list(\"___W__\"),\n",
    "    list(\"_W____\"),\n",
    "]\n",
    "\n",
    "game_over_board_1 = [\n",
    "    list(\"______\"),\n",
    "    list(\"_W____\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "game_over_board_2 = [\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_B____\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "max_depth_board_1 = [\n",
    "    list(\"______\"),\n",
    "    list(\"W_____\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_____B\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "max_depth_board_2 = [\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"W_____\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_____B\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "player_switching_board = [\n",
    "    list(\"___B__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_B__B_\"),\n",
    "    list(\"W____W\"),\n",
    "    list(\"______\"),\n",
    "    list(\"___W__\"),\n",
    "]\n",
    "\n",
    "def invoke_search_fn(search_fn, board, max_depth, current_player):\n",
    "    if \"alpha_beta\" in search_fn.__name__:\n",
    "        return search_fn(board, 0, max_depth, -INF, INF, current_player)\n",
    "    else:\n",
    "        return search_fn(board, 0, max_depth, current_player)\n",
    "\n",
    "def test_board_preservation(search_fn):\n",
    "    control_board = copy.deepcopy(preservation_board)\n",
    "    input_board = copy.deepcopy(preservation_board)\n",
    "    invoke_search_fn(search_fn, input_board, 2, Player.BLACK)\n",
    "    assert control_board == input_board, \"One or more of your functions may be modifying the original board.\"\n",
    "\n",
    "def test_game_over(search_fn, board, expected_score):\n",
    "    score, move = invoke_search_fn(search_fn, board, 1, Player.BLACK)\n",
    "    assert score == expected_score, f\"Your function might not have terminated correctly. when the game is over.\\nExpected score: {expected_score}, Actual score: {score}\"\n",
    "    assert move == MOVE_NONE, \"Your function might not be returning MOVE_NONE when no moves are possible or it might be generating moves for the opponent instead.\"\n",
    "\n",
    "def test_max_depth(search_fn, board, current_player, expected_moves):\n",
    "    score, move = invoke_search_fn(search_fn, board, 1, current_player)\n",
    "    assert score == 0, f\"Your function may not be terminating at cut off depth or you may be initialising {current_player.value}'s score incorrectly.\\nExpected score: 0, Actual score: {score}\"\n",
    "    assert move in expected_moves, f\"Your function does not move {current_player.value} pieces during {current_player.value}'s turn, or initialises {current_player.value}'s score incorrectly or terminates early.\"\n",
    "\n",
    "def test_player_switching(search_fn, current_player):\n",
    "    score, _ = invoke_search_fn(search_fn, player_switching_board, 2, current_player)\n",
    "    assert score != 2, \"Your transition function may not be switching player's colours correctly after making a move.\"\n",
    "    assert score == 0, \"Your function may not be making the most optimal move at each depth.\"\n",
    "\n",
    "def test_search(search_fn, board, max_depth, current_player, expected_score, expected_moves):\n",
    "    score, move = invoke_search_fn(search_fn, board, max_depth, current_player)\n",
    "    assert score == expected_score, f\"Final evaluation score should be {expected_score} instead of {score}.\"\n",
    "    assert move in expected_moves, f\"Your function does not correctly move {current_player.value}'s pieces despite having the correct evaluation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Test cases\n",
    "test_board_preservation(minimax_alpha_beta)\n",
    "test_game_over(minimax_alpha_beta, game_over_board_1, -WIN)\n",
    "test_game_over(minimax_alpha_beta, game_over_board_2, WIN)\n",
    "test_max_depth(minimax_alpha_beta, max_depth_board_1, Player.BLACK, [((3, 5), (4, 4)), ((3, 5), (4, 5))])\n",
    "test_max_depth(minimax_alpha_beta, max_depth_board_2, Player.WHITE, [((2, 0), (1, 0)), ((2, 0), (1, 1))])\n",
    "test_player_switching(minimax_alpha_beta, Player.BLACK)\n",
    "test_player_switching(minimax_alpha_beta, Player.WHITE)\n",
    "\n",
    "test_search(minimax_alpha_beta, board_41, 3, Player.BLACK, WIN, [((3, 4), (4, 5))])\n",
    "test_search(minimax_alpha_beta, board_42, 6, Player.BLACK, -WIN, [((0, 4), (1, 4)), ((0, 4), (1, 5)), ((1, 2), (2, 2)), ((1, 2), (2, 1)), ((1, 2), (2, 3)), ((1, 3), (2, 3)), ((1, 3), (2, 2)), ((1, 3), (2, 4))])\n",
    "test_search(minimax_alpha_beta, board_33, 3, Player.WHITE, -WIN, [((2, 0), (1, 0)), ((2, 0), (1, 1))])\n",
    "test_search(minimax_alpha_beta, board_34, 3, Player.WHITE, -1, [((3, 1), (2, 2)), ((4, 2), (3, 3)), ((4, 4), (3, 3)), ((4, 4), (3, 5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Function\n",
    "\n",
    "Phew, we finish the search algorithm! But, our heuristic function is too simple - it may not give the best evaluation for a position and we need a better one. Therefore, you shall implement the improved heuristic function described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3: Implement an improved heuristic function\n",
    "\n",
    "Recall that the heuristic function should return a larger value when black is closer to winning. If black is closer to winning, black should have more pieces closer to row 5 compared to white having pieces closer to row 0. Of course this is not necessarily the case since you only need one piece to make it through while the rest remain behind, but this is just a heuristic after all. Thus, in this task you are to implement a heuristic that performs better than the previous one, where positions should be taken into account instead of just the number of pieces left. \n",
    "\n",
    "Generally, more white pieces closer to the end point should signify a lower heuristic score, while more black pieces closer to the end point will create a higher heuristic score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_evaluate(state: State) -> Score:\n",
    "    \"\"\"\n",
    "    Returns the score of the current position with an improved heuristic.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An improved evaluation (as a Score).\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# Test cases\n",
    "board_51 = [\n",
    "    list(\"___B__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"__B___\"),\n",
    "    list(\"_WWW__\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "board_52 = [\n",
    "    list(\"___BW_\"),\n",
    "    list(\"___W__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "board_53 = [\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"__B___\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "board_54 = [\n",
    "    list(\"__B___\"),\n",
    "    list(\"__WB__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "assert improved_evaluate((board_51, Player.BLACK)) > heuristic((board_51, Player.BLACK)), \"Your improved evaluation function should return higher than the original heuristic, as black is winning.\"\n",
    "assert improved_evaluate((board_52, Player.BLACK)) == -WIN, \"Your improved evaluation function does not correctly evaluate won positions.\"\n",
    "assert improved_evaluate((board_53, Player.BLACK)) == WIN, \"Your improved evaluation function does not correctly evaluate won positions.\"\n",
    "assert improved_evaluate((board_54, Player.BLACK)) < heuristic((board_54, Player.BLACK)), \"Your improved evaluation function should return smaller than the original heuristic, as white is winning.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "\n",
    "To assist with your implementation, we have provided some examples as test cases. These are not sufficient to ensure that your code works correctly, and we encourage you to write your own additional test cases to test and debug your code.\n",
    "\n",
    "Note that your answers may be slightly different from the answers provided since multiple valid solutions may exist. During grading, your code will be evaluated on hidden test cases on top of the ones we have provided to check the quality of your search functions and algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs2109-2526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
