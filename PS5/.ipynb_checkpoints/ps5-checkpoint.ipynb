{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd5fdf63-0a79-4490-aa8f-3669ba1a7f58",
   "metadata": {},
   "source": [
    "# Problem Set 5: Neural Networks\n",
    "\n",
    "**Release Date:** 27 Oct 2025\n",
    "\n",
    "**Due Date:** 15 Nov 2025"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b3fadaa-a686-498a-b9c0-d56a6c8b591f",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "While fundamental understanding is crucial and the ability to build things from scratch is helpful, it can be unnecessarily time consuming. In Deep Learning (DL) models like neural networks with many layers, backpropagating manually is error-prone, and specifying the exact behaviour of every layer from first principles would be unreasonably tedious. We find it critical to be familiar with **at least one** Machine Learning library for pragmatic purposes.\n",
    "\n",
    "![PyTorch](images/logo.png)\n",
    "\n",
    "`PyTorch` is one of the most widely-used DL libraries. It offers a very Pythonic API to build layers and compose them together. In fact, data processing is also made easy using the multitude of tools and wrappers that are at your disposal. Of course, there are other popular libraries such as `TensorFlow`, but they require you to understand \"computation graphs\", which we feel makes it less accessible for beginners.\n",
    "\n",
    "In **Problem Set 5**, we will guide you through the `PyTorch` API by having you build a simple deep neural network and training it locally on your system via backpropagation and stochastic gradient descent. Subsequently, you will be building a __Convolutional Neural Network__ (CNN/ConvNet) and training it on two datasets, *MNIST* and *CIFAR-10*, and learn __data augmentation__ to enhance your dataset. We will then learn the details of RNN, their applications to sequential data, and using a RNN to model and predict patterns in time-series data. Finally, we shall explore the incorporation of attention layers as a first step toward building a transformer architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261330f",
   "metadata": {},
   "source": [
    "### Structure of this Notebook\n",
    "While this problem set is undeniably longer, you might notice a lot of the cells function as **Demos**, leaving only a small proportion as **Tasks** for you to complete. These **Demos** walk through certain building blocks which are likely to help you build a deeper understanding, whereas the **Tasks** are more application-focused (i.e. making use of `PyTorch`'s powerful API). There is also a separate file `ps5_supplementary.ipynb` which explains certain concepts in greater detail. While optional to read, we encourage you to do so!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e81322e",
   "metadata": {},
   "source": [
    "### Required Files\n",
    "* ps5.ipynb\n",
    "* data/\n",
    "    * review_train.csv\n",
    "    * review_test.csv\n",
    "\n",
    "### Plagiarism Policy\n",
    "\n",
    "Please refer to our [Course Policies](https://canvas.nus.edu.sg/courses/77861/pages/course-policies)\n",
    "\n",
    "_Honour Code: Note that plagiarism will not be condoned! You may discuss with your classmates and check the internet for references, but you MUST NOT submit any code/report/explanation that is copied directly from other sources!_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42025bf4",
   "metadata": {},
   "source": [
    "### Post-Problem Set Survey\n",
    "Your feedback is important to us! After completing Problem Set 5, please take a moment to share your thoughts by filling out this [survey](https://coursemology.org/courses/3095/surveys/2719)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26e8fb6f",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The following lines of code import packages and functions that are necessary\n",
    "for the following tasks.\n",
    "\n",
    "As a reminder, please **do not** modify the following lines of code by adding,\n",
    "removing or modifying the specified imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a167fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FIRST\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from numpy import allclose, isclose\n",
    "\n",
    "from collections.abc import Callable\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da8e3c54",
   "metadata": {},
   "source": [
    "# 1 - Neural Networks using PyTorch layers\n",
    "Before starting, we recommend reading **Extra Chapter 1** in `ps5_supplementary.ipynb` to understand `PyTorch` tensors, and get an idea of how one might implement gradient descent without relying `PyTorch`. Then, you'll appreciate the convenience of the powerful `PyTorch` library!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "763f853c",
   "metadata": {},
   "source": [
    "### Demo 1.1 - nn.Module\n",
    "\n",
    "The `nn.Module` class is an interface that houses two main methods: `__init__`, where we instantiate our layers and activation functions, and `forward`, that performs the forward pass.\n",
    "\n",
    "To create our own neural network, we will inherit from the nn.Module parent class and call `super().__init__()` within our constructor to create our module. Next, we will implement the `forward` function within our class so we can call it from our module to perform the forward pass. \n",
    "\n",
    "In this example, we define a custom LinearLayer class that inherits from nn.Module. The __init__ method initializes the weight and bias parameters as nn.Parameter objects, which are special types of tensors that require gradients to be computed during the backward pass.\n",
    "\n",
    "The forward method defines the forward pass of the linear layer. It takes a tensor x as input and computes the matrix multiplication of x and self.weight using the torch.matmul function, and then adds self.bias.\n",
    "\n",
    "We also created our own activation function which uses `torch.sin` by inheriting from nn.Module.\n",
    "\n",
    "Finally, in our Model, we can combine our own LinearLayers together with our SineActivation to process our input data using the forward function. In later sections, you will see how we can train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b196ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear layer using nn.Module\n",
    "class LinearLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear layer as a subclass of `nn.Module`.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, output_dim))\n",
    "        self.bias = nn.Parameter(torch.randn(output_dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(x, self.weight) + self.bias\n",
    "    \n",
    "class SineActivation(nn.Module):\n",
    "    \"\"\"\n",
    "    Sine activation layer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sin(x)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network created using `LinearLayer` and `SineActivation`.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_classes: int):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = LinearLayer(input_size, hidden_size)\n",
    "        self.act = SineActivation()\n",
    "        self.l2 = LinearLayer(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.l1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "    \n",
    "input_size = 1\n",
    "hidden_size = 1\n",
    "num_classes = 1\n",
    "\n",
    "model = Model(input_size, hidden_size, num_classes)\n",
    "\n",
    "x = torch.tensor([[1.0]])\n",
    "output = model(x)\n",
    "print(\"Original value: \", x)\n",
    "print(\"Value after being processed by Model: \", output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84a88b6a",
   "metadata": {},
   "source": [
    "_Extra: We can also define a `backward` function to perform backpropagation which will not be required in this problem set._\n",
    "\n",
    "In the following trivial example, the Squared module takes an input x and returns x**2. The backward method calculates the gradient of the output with respect to the input, based on the gradients of the output grad_output.\n",
    "\n",
    "We can define the backward function for functions that are not fully differentiable that we still wish to use in our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc40790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squared(nn.Module):\n",
    "    \"\"\"\n",
    "    Module that returns x**2.\n",
    "    \"\"\"\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.x = x\n",
    "        return x**2\n",
    "\n",
    "    def backward(self, grad_output: torch.Tensor) -> torch.Tensor:\n",
    "        grad_input = 2 * self.x * grad_output\n",
    "        return grad_input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4b0474e",
   "metadata": {},
   "source": [
    "### Demo 1.2 - Activation Functions\n",
    "\n",
    "Activation functions introduce non-linearity into the output of a neuron, allowing the NN to learn non-linear functions. Otherwise, our entire network effectively becomes equivalent to a linear model, preventing us from modelling complex representations based on our inputs. Thus, activation functions are essential, and the choice of activation function can impact your model's effectiveness depending on your input data and the problem you're trying to solve.\n",
    "\n",
    "####  For the hidden layers, there are several commonly used activation functions:\n",
    "\n",
    "**ReLU** (Rectified Linear Unit): Maps non-positive inputs to 0 and positive inputs to their original value. It is mainly used in hidden layers because it is fast to compute, has sparse activations, and helps to mitigate the vanishing gradient problem, where the gradients can become very small and cause the model to learn slowly.\n",
    "\n",
    "**Tanh** (Hyperbolic Tangent): Maps input values to the range [-1, 1]. It is similar to Sigmoid, but instead of producing output values in the range [0, 1], it produces output values in the range [-1, 1]. Tanh is useful for solving problems where you want the activations to be centered around zero, such as in recurrent neural networks.\n",
    "\n",
    "**Sigmoid**: Maps its input values to the range [0, 1]. It is less commonly used in hidden layers because it has a relatively slow convergence rate and can introduce saturation, where the output values become very small or very large, which can make it difficult for the gradients to flow through the model.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/sigmoid_tanh_relu.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "#### For the output layer, the choice of activation function depends on the problem you're trying to solve. Here are some common choices:\n",
    "\n",
    "**Sigmoid**: The Sigmoid activation function maps input values to the range [0, 1]. It is commonly used for binary classification problems where the network produces a probability of one of two classes. In this case, the Sigmoid activation maps the output to a probability distribution over the two classes.\n",
    "\n",
    "**Softmax**: The Softmax activation function is a generalization of the Sigmoid activation that maps input values to a probability distribution over multiple classes. It is commonly used for multiclass classification problems. The Softmax activation function is used to convert the raw scores produced by the network into a probability distribution over the classes.\n",
    "\n",
    "**Linear**: For regression problems, we could just finish with a linear layer as we don't have to dramatically morph the output into something particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = torch.linspace(-2, 2, 100)\n",
    "sigmoid_output = nn.Sigmoid()(x_sample).detach().numpy()\n",
    "tanh_output = nn.Tanh()(x_sample).detach().numpy()\n",
    "relu_output = nn.ReLU()(x_sample).detach().numpy()\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(6)\n",
    "plt.xlabel('x - axis')\n",
    "plt.ylabel('y - axis')\n",
    "plt.title(\"Input: 100 x-values between -2 to 2 \\n\\n Output: Corresponding y-values after passed through each activation function\\n\", fontsize=16)\n",
    "plt.axvline(x=0, color='r', linestyle='dashed')\n",
    "plt.axhline(y=0, color='r', linestyle='dashed')\n",
    "plt.plot(x_sample, sigmoid_output)\n",
    "plt.plot(x_sample, tanh_output)\n",
    "plt.plot(x_sample, relu_output)\n",
    "plt.legend([\"\",\"\",\"Sigmoid Output\", \"Tanh Output\", \"ReLU Output\"])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3baf89e",
   "metadata": {},
   "source": [
    "### Demo 1.3 - Forward pass (NN)\n",
    "\n",
    "In Extra Chapter 1, we manually created the Linear layers and explicitly specified weights and biases for the forward pass to connect every input neuron to every output neuron. Luckily, we can let `PyTorch` do all that for us instead.\n",
    "\n",
    "Let's use `nn.Linear(in_dimensions, out_dimensions)` which represents a fully connected layer with bias automatically included. We can also choose to remove the bias column by simply calling `nn.Linear(in_dimensions, out_dimensions, bias=False)` instead.  \n",
    "\n",
    "<div>\n",
    "<img src=\"images/toy_nn.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "With `PyTorch`, it is easy to combine many different types of layers and activation functions to create neural networks.\n",
    "\n",
    "The model has been built for you in `__init__`. We implement the `forward` method, making use of the layers `self.l1`, `self.l2`, and the activation function `self.relu`. Observe that we combine the linear layers and the activation function in the forward pass function!\n",
    "\n",
    "_Extra: PyTorch has many other layers implemented for various model architectures.  \n",
    "You can read more in the glossary as well as in the docs: https://pytorch.org/docs/stable/nn.html  \n",
    "For now, we will only be using fully connected `nn.Linear` layers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO\n",
    "class MyFirstNeuralNet(nn.Module):\n",
    "    def __init__(self): # set the arguments you'd need\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(1, 2) # bias included by default\n",
    "        self.l2 = nn.Linear(2, 1) # bias included by default\n",
    "        self.relu = nn.ReLU()\n",
    " \n",
    "    # Task 1.1: Forward pass\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Forward pass to process input through two linear layers and ReLU activation function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : A tensor of of shape (n, 1) where n is the number of training instances\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tensor of shape (n, 1)\n",
    "        '''\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b7b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to check\n",
    "x_sample = torch.linspace(-2, 2, 5).reshape(-1, 1)\n",
    "\n",
    "model = MyFirstNeuralNet()\n",
    "\n",
    "state_dict = OrderedDict([\n",
    "    ('l1.weight', torch.tensor([[1.],[-1.]])),\n",
    "    ('l1.bias',   torch.tensor([-1., 1.])),\n",
    "    ('l2.weight', torch.tensor([[1., 1.]])),\n",
    "    ('l2.bias',   torch.tensor([0.]))\n",
    "])\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "student1 = model.forward(x_sample).detach().numpy()\n",
    "output1 = [[3.], [2.], [1.], [0.], [1.]]\n",
    "\n",
    "assert allclose(student1, output1, atol=1e-5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd2e0500",
   "metadata": {},
   "source": [
    "### Demo 1.4 - Optimisers in PyTorch\n",
    "Recall that `PyTorch` can automatically handle the heavy lifting of calculus: when you run **loss.backward()**, the derivative of the loss with respect to a parameter is computed and stored automatically in that parameter's **.grad** attribute.\n",
    "\n",
    "The **Optimizer** goes one step further—It also automatically uses the calculated gradient to actually update the parameter's value for us. We have the choice of which optimizer to use, as they follow different optimization algorithms like **SGD** or **Adam**.\n",
    "\n",
    "In the following code example, we simply demo a few basic functionalities of optimisers. Later, we'll see an actual optimizer at work to train a Neural Net.\n",
    "\n",
    "We first create a tensor x with requires_grad set to True. Next, we define our loss function to be the simple equation $y = x^2 + 2x$. Next, we define an optimiser (in this case Stochastic Gradient Descent, SGD) and pass it our tensor $x$ as a parameter to optimise. After updating the gradient stored in $x$ using `backward()`, we will call the `step()` function to let the optimiser update $x$. We will then set the gradient of our tensor $x$ back to zero using `zero_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "#Loss function\n",
    "y = x ** 2 + 2 * x\n",
    "\n",
    "# Define an optimizer, pass it our tensor x to update\n",
    "optimiser = torch.optim.SGD([x], lr=0.1)\n",
    "\n",
    "# Perform backpropagation\n",
    "y.backward()\n",
    "\n",
    "print(\"Value of x before it is updated by optimiser: \", x)\n",
    "print(\"Gradient stored in x after backpropagation: \", x.grad)\n",
    "\n",
    "# Call the step function on the optimizer to update weight\n",
    "optimiser.step()\n",
    "\n",
    "#Weight update, x = x - lr * x.grad = 1.0 - 0.1 * 4.0 = 0.60\n",
    "print(\"Value of x after it is updated by optimiser: \", x)\n",
    "\n",
    "# Set gradient of weight to zero\n",
    "optimiser.zero_grad()\n",
    "print(\"Gradient stored in x after zero_grad is called: \", x.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1efa2827",
   "metadata": {},
   "source": [
    "### Demo 1.5 - Training Your First Neural Net\n",
    "\n",
    "Now, let's make use of an optimiser to train our neural network built earlier in Task 1.1!\n",
    "\n",
    "We will using `torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0)` which implements stochastic gradient descent for us. As mentioned previously, `optimiser.zero_grad()` will set all the gradients to zero to prevent accumulation of previous gradients gathered during backpropagation. `optimiser.step()` tells the optimiser to update the model weights based on the gradients of our parameters.\n",
    "\n",
    "In our example below, `optimiser.zero_grad()` at the start of the loop clears the gradient from previous iterations of backpropagation. Then after computing loss and making the prediction **y_pred**, we call `loss.backward()` to let `PyTorch` carry out the backpropagation for us. Finally, gradients for each parameter are used to update our model weights using `optimiser.step()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6) # Set seed to some fixed value\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "model = MyFirstNeuralNet()\n",
    "# the optimizer controls the learning rate\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "x = torch.linspace(-10, 10, 1000).reshape(-1, 1)\n",
    "y = torch.abs(x-1)\n",
    "\n",
    "print('Epoch', 'Loss', '\\n-----', '----', sep='\\t')\n",
    "for i in range(1, epochs+1):\n",
    "    # reset gradients to 0\n",
    "    optimiser.zero_grad()\n",
    "    # get predictions\n",
    "    y_pred = model(x)\n",
    "    # compute loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # update the model weights\n",
    "    optimiser.step()\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print (f\"{i:5d}\", loss.item(), sep='\\t')\n",
    "\n",
    "y_pred = model(x)\n",
    "plt.plot(x, y, linestyle='solid', label='|x-1|')\n",
    "plt.plot(x, y_pred.detach().numpy(), linestyle='dashed', label='perceptron')\n",
    "plt.axis('equal')\n",
    "plt.title('Fit NN on y=|x-1| function')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd0a78aa",
   "metadata": {},
   "source": [
    "### Tip: Save and load models\n",
    "\n",
    "Your model weights are stored within the model itself.  \n",
    "You may save/load the model weights:\n",
    "```\n",
    "torch.save(model.state_dict(), \"path/to/model_state_dict\")\n",
    "\n",
    "model = MyFirstNeuralNet()\n",
    "model.load_state_dict(torch.load(\"path/to/model_state_dict\"))\n",
    "```\n",
    "\n",
    "Alternatively, you can save/load the entire model using\n",
    "```\n",
    "torch.save(model, \"path/to/model\")\n",
    "\n",
    "model = torch.load(\"path/to/model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to view your model weights\n",
    "print(\"--- Submit the OrderedDict below ---\")\n",
    "print(model.state_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f3d9a8a",
   "metadata": {},
   "source": [
    "### Using NN to recognize handwritten digits\n",
    "\n",
    "Now we will be building a neural network to classify images to their respective digits.  \n",
    "\n",
    "You will build and train a model on the classic **MNIST Handwritten Digits** dataset. Each grayscale image is a $28 \\times 28$ tensor that looks something like:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" width=\"500\" />\n",
    "\n",
    "MNIST is a classification problem and the task is to take in an input image and classify them into one of ten buckets: the digits from $0$ to $9$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "433b0e36",
   "metadata": {},
   "source": [
    "### Demo 1.6 - Loading an external dataset\n",
    "\n",
    "The cell below imports the MNIST dataset, which is already pre-split into train and test sets.  \n",
    "\n",
    "The download takes approximately 63MB of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2add2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL – THIS DOWNLOADS THE MNIST DATASET\n",
    "# RUN THIS CELL BEFORE YOU RUN THE REST OF THE CELLS BELOW\n",
    "from torchvision import datasets\n",
    "\n",
    "# This downloads the MNIST datasets ~63MB\n",
    "mnist_train = datasets.MNIST(\"./\", train=True, download=True)\n",
    "mnist_test  = datasets.MNIST(\"./\", train=False, download=True)\n",
    "\n",
    "x_train = mnist_train.data.reshape(-1, 784) / 255\n",
    "y_train = mnist_train.targets\n",
    "    \n",
    "x_test = mnist_test.data.reshape(-1, 784) / 255\n",
    "y_test = mnist_test.targets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70e06d36",
   "metadata": {},
   "source": [
    "### Task 1.1 - Define the model architecture and implement the forward pass\n",
    "Create a 3-layer network in the `__init__` method of the model `DigitNet`.  \n",
    "These should all be `Linear` layers and correspond to the following architecture:\n",
    "\n",
    "<div>\n",
    "<img src=\"images/img_linear_nn.png\", width=700>\n",
    "</div>\n",
    "\n",
    "In our data, a given image $x$ has been flattened from a 28x28 image to a 784-length array.\n",
    "\n",
    "After initializing the layers, stitch them together in the `forward` method. Your network should look like so:\n",
    "\n",
    "$$x \\rightarrow \\text{Linear(512)} \\rightarrow \\text{ReLU} \\rightarrow \\text{Linear(128)} \\rightarrow \\text{ReLU} \\rightarrow \\text{Linear(10)} \\rightarrow \\text{Softmax} \\rightarrow \\hat{y}$$\n",
    "\n",
    "**Softmax Layer**: The final softmax activation is commonly used for classification tasks, as it normalizes the input vector into a probability mass vector which sums up to 1. This is a natural choice of final activation when trying to model probability distributions, like we are doing here.\n",
    "\n",
    "*Note: When using `torch.softmax(...)` on the final layer, ensure you are applying it on the correct dimension (as you did in NumPy via the `axis` argument in popular methods)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitNet(nn.Module):\n",
    "    def __init__(self, input_dimensions: int, num_classes: int): # set the arguments you'd need\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        YOUR CODE HERE\n",
    "        - DO NOT hardcode the input_dimensions, use the parameter in the function\n",
    "        - Your network should work for any input and output size \n",
    "        - Create the 3 layers (and a ReLU layer) using the torch.nn layers API\n",
    "        \"\"\"\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs the forward pass for the network.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Input tensor (batch size is the entire dataset)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            The output of the entire 3-layer model.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        YOUR CODE\n",
    "        \n",
    "        - Pass the inputs through the sequence of layers\n",
    "        - Run the final output through the Softmax function on the right dimension!\n",
    "        \"\"\"\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fdb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "model = DigitNet(784, 10)\n",
    "assert [layer.detach().numpy().shape for name, layer in model.named_parameters()] \\\n",
    "        == [(512, 784), (512,), (128, 512), (128,), (10, 128), (10,)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "921fec58",
   "metadata": {},
   "source": [
    "### Task 1.2 - Training Loop\n",
    "\n",
    "Similar to what we did above, implement the function `train_model` that performs the following for every epoch/iteration:\n",
    "\n",
    "1. set the optimizer's gradients to zero\n",
    "2. forward pass\n",
    "3. calculate the loss\n",
    "4. backpropagate using the loss\n",
    "5. take an optimzer step to update weights\n",
    "\n",
    "This time, use the Adam optimiser to train the network.\n",
    "<br/>\n",
    "Use Cross-Entropy Loss, since we are performing a classification.\n",
    "<br/>\n",
    "Train for 20 epochs.  \n",
    "\n",
    "*Note: refer to the command glossary to find out how to instantiate optimisers, losses, and more*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7da065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train: torch.Tensor, y_train: torch.Tensor, epochs: int = 20):\n",
    "    \"\"\"\n",
    "    Trains the model for 20 epochs/iterations\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        x_train : A tensor of training features of shape (60000, 784)\n",
    "        y_train : A tensor of training labels of shape (60000, 1)\n",
    "        epochs  : Number of epochs, default of 20\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        The final model \n",
    "    \"\"\"\n",
    "    model = DigitNet(784, 10)\n",
    "\n",
    "    optimiser = torch.optim.Adam(model.parameters()) # use Adam\n",
    "    loss_fn = nn.CrossEntropyLoss()   # use CrossEntropyLoss\n",
    "\n",
    "    for i in range(epochs):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "    return model\n",
    "                \n",
    "digit_model = train_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "x_train_new = torch.rand(5, 784, requires_grad=True)\n",
    "y_train_new = ones = torch.ones(5, dtype=torch.uint8)\n",
    "\n",
    "assert type(train_model(x_train_new, y_train_new)) == DigitNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c70083f",
   "metadata": {},
   "source": [
    "### Demo 1.7 - Explore your model\n",
    "\n",
    "Now that we have trained the model, let us run some predictions on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5199255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a demonstration: You can use this cell for exploring your trained model\n",
    "\n",
    "idx = 0 # try on some index\n",
    "\n",
    "scores = digit_model(x_test[idx:idx+1])\n",
    "_, predictions = torch.max(scores, 1)\n",
    "print(\"true label:\", y_test[idx].item())\n",
    "print(\"pred label:\", predictions[0].item())\n",
    "\n",
    "plt.imshow(x_test[idx].numpy().reshape(28, 28), cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d87efe74",
   "metadata": {},
   "source": [
    "### Task 1.3 - Evaluate the model\n",
    "\n",
    "Now that we have trained the model, we should evaluate it using our test set.  \n",
    "We will be using **accuracy** (Boolean; whether the model predicted the correct label) to measure performance.  \n",
    "\n",
    "Recall that our model takes in a $(n$ x $784)$ tensor and returns a $(n$ x $10)$ tensor of probability scores for each of the 10 classes. But our final guess should be one label, not a probability vector. An extra step is needed here to extract the best guess from the output vector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(scores: torch.Tensor, labels: torch.Tensor) -> int | float:\n",
    "    \"\"\"\n",
    "    Helper function that returns accuracy of model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        scores : The raw softmax scores of the network\n",
    "        labels : The ground truth labels\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Accuracy of the model. Return a number in range [0, 1].\n",
    "        0 means 0% accuracy while 1 means 100% accuracy\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "scores = digit_model(x_test) # n x 10 tensor\n",
    "get_accuracy(scores, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "scores = torch.tensor([[0.4118, 0.6938, 0.9693, 0.6178, 0.3304, 0.5479, 0.4440, 0.7041, 0.5573,\n",
    "         0.6959],\n",
    "        [0.9849, 0.2924, 0.4823, 0.6150, 0.4967, 0.4521, 0.0575, 0.0687, 0.0501,\n",
    "         0.0108],\n",
    "        [0.0343, 0.1212, 0.0490, 0.0310, 0.7192, 0.8067, 0.8379, 0.7694, 0.6694,\n",
    "         0.7203],\n",
    "        [0.2235, 0.9502, 0.4655, 0.9314, 0.6533, 0.8914, 0.8988, 0.3955, 0.3546,\n",
    "         0.5752],\n",
    "        [0,0,0,0,0,0,0,0,0,1]])\n",
    "y_true = torch.tensor([5, 3, 6, 4, 9])\n",
    "acc_true = 0.4\n",
    "assert isclose(get_accuracy(scores, y_true),acc_true) , \"Mismatch detected\"\n",
    "print(\"passed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21d43acd",
   "metadata": {},
   "source": [
    "# 2 - Convolutional Neural Networks (CNN)\n",
    "\n",
    "Let's work on the MNIST handwritten digits classification problem again but this time with CNNs. Now we'll use the original images in the form of $1 \\times 28 \\times 28$ tensors, where $28$ is the image height and width, and $1$ is the number of colour channels (grayscale image in this case).\n",
    "\n",
    "A CNN is ideal for image classification because it employs convolutional operations to leverage the 2D spatial structure of an image, enabling powerful and efficient feature extraction.\n",
    "\n",
    "Read **Extra Chapter 2** in `ps5_supplementary.ipynb` for an explanation and implementation details of **convolution** and **pooling**, two fundamental concepts behind the magic of CNNs!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "698c6b40",
   "metadata": {},
   "source": [
    "### Concept: DataLoaders\n",
    "\n",
    "PyTorch __DataLoaders__ accept datasets and can iterate through the datasets as we deem fit.\n",
    "\n",
    "`train_loader = torch.utils.data.DataLoader(mnist_train, shuffle=True, batch_size=256)` means that this dataloader takes in the MNIST training data, and outputs training features and labels in batches of 256. It also reshuffles all the data in the dataset for the next epoch once it has outputted all the data in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e605339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not remove this cell\n",
    "# run this before moving on\n",
    "\n",
    "T = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "Note: If you updated the path to the directory containing `MNIST` \n",
    "directory, please update it here as well.\n",
    "\"\"\"\n",
    "mnist_train = datasets.MNIST(\"./\", train=True, download=False, transform=T)\n",
    "mnist_test = datasets.MNIST(\"./\", train=False, download=False, transform=T)\n",
    "\n",
    "\"\"\"\n",
    "if you feel your computer can't handle too much data, you can reduce the batch\n",
    "size to 64 or 32 accordingly, but it will make training slower. \n",
    "\n",
    "We recommend sticking to 128 but do choose an appropriate batch size that your\n",
    "computer can manage. The training phase tends to require quite a bit of memory.\n",
    "\"\"\"\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, shuffle=True, batch_size=256)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to edit this. Just run the cell and move on\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ffc08d2",
   "metadata": {},
   "source": [
    "### Demo 2.1: Building a Vanilla ConvNet\n",
    "\n",
    "Let's walk through how to build a ConvNet using PyTorch layers. You can refer to the attached command glossary to read more about the layers. We'll follow the following architecture:\n",
    "\n",
    "$$\n",
    "\\text{Conv(32, (3,3))} \\rightarrow \\text{MP(2,2)} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\text{Conv(64, (3,3))} \\rightarrow \\text{MP(2,2)} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\text{Flat} \\\\ \\rightarrow \\text{L(1600, 256)} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\text{L(256, 128)} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\text{L(128, 10)} \\rightarrow \\text{Softmax}\n",
    "$$\n",
    "\n",
    "where \n",
    "- [`Conv`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) is a Convolution layer with the specified output channels and kernel size, with no padding and a stride of 1 by default.\n",
    "\n",
    "- [`MP`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) is the Max Pooling layer with the specified kernel size, with no padding, the stride set to the same shape as the kernel by default.\n",
    "\n",
    "- [`LReLU`](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html) is Leaky ReLU with the specified negative slope.\n",
    "\n",
    "- `Flat` is the flattening operation, which should flatten/reshape the tensor from a multi-dimensional tensor (batch_size, num_channels, width, height) into a \"flat\" tensor (batch_size, num_channels x width x height). The 2-dimensional result represents that each sample has only 1 dimension of \"flattened\" data. This has already been implemented for you\n",
    "\n",
    "- [`L`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) is a fully-connected layer with the specified input and output features.\n",
    "\n",
    "__Note:__ For all your networks hereon, the only constructor argument is `classes`. Do not add any other parameters to the `__init__` method. Remember not to hardcode for the number of classes and use the `classes` argument instead.\n",
    "\n",
    "__Note:__ There is no need to include a Softmax layer in your neural network because we will be using [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) as our loss function later, which already applies Softmax implicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b951f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo\n",
    "class RawCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN model using Conv2d and MaxPool2d layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, classes: int):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        classes: integer that corresponds to the number of classes for MNIST\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(1, 32, (3,3))\n",
    "        self.mp1 = nn.MaxPool2d((2,2))\n",
    "        self.lrelu = nn.LeakyReLU(0.1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, (3,3))\n",
    "        self.mp2 = nn.MaxPool2d((2,2))\n",
    "\n",
    "        self.l1 = nn.Linear(64*5*5, 256)\n",
    "        self.l2 = nn.Linear(256, 128)\n",
    "        self.l3 = nn.Linear(128, classes)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = self.lrelu(x)   \n",
    "        \n",
    "        x = x.view(-1, 64*5*5) # Flattening – do not remove this line\n",
    "\n",
    "        x = self.l1(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.lrelu(x)\n",
    "        out = self.l3(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Test the network's forward pass\n",
    "num_samples, num_channels, width, height = 20, 1, 28, 28\n",
    "x = torch.rand(num_samples, num_channels, width, height)\n",
    "net = RawCNN(10)\n",
    "y = net(x)\n",
    "print(y.shape) # torch.Size([20, 10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df3949cc",
   "metadata": {},
   "source": [
    "### Concept: Dropout\n",
    "\n",
    "__Dropout__ (*Srivastava et al., 2014*) is a regularisation technique that randomly shuts off neurons in a given layer. This means the output of the neuron is made to be __zero__. When building the dropout layer, we need to specify a probability value `p` that a neuron gets shut off.\n",
    "\n",
    "A visualisation of one realisation when using dropout:\n",
    "\n",
    "<img src=\"images/dropout.png\" width=600>\n",
    "\n",
    "### How Dropout helps\n",
    "Dropout randomly disables neurons during training, which has a powerful regularization effect. By forcing the network to achieve good results with different subsets of active neurons at every step, it essentially trains an ensemble of many different, sparser networks simultaneously. This prevents overfitting because no single neuron can become overly specialized, ensuring a more robust and generalized model.\n",
    "\n",
    "#### Dropout in PyTorch\n",
    "To use Dropout in a network, we can create a `Dropout` layer in our `__init__` method of the model class:\n",
    "\n",
    "```python\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ..., drop_prob):\n",
    "        super().__init__()\n",
    "        self.l1 = ...\n",
    "        ...\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "        ...\n",
    "        self.ln = ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        ...\n",
    "        x = self.dropout(x)\n",
    "        ...\n",
    "        out = ...\n",
    "        \n",
    "        return out\n",
    "```\n",
    "\n",
    "__Note:__ Other that `nn.Dropout`, there is a `nn.Dropout2d` in PyTorch. Instead of randomly zero-ing out neurons, `Dropout2d` randomly zero-es out the entire channels of the input. \n",
    "\n",
    "`nn.Dropout` is best used with non-spatial data or data that has been flattened, which is typical for fully connected layers. `nn.Dropout2d` is designed for spatial data, making it ideal for use right after convolutional and pooling layers in CNNs.\n",
    "\n",
    "For the sake of this problem set, You should choose one of them to be but __NOT both__ in your neural network.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a23c4c6",
   "metadata": {},
   "source": [
    "### Task 2.1: Building a ConvNet with Dropout\n",
    "\n",
    "Let's build the exact same network but with Dropout inside the architecture. You can refer to the attached command glossary to read more about the layers. Use the following architecture:\n",
    "\n",
    "$$\n",
    "\\text{Conv(32, (3,3))} \\rightarrow \\text{MP(2,2)} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\textbf{DO(prob)} \\rightarrow \\\\\n",
    "\\text{Conv(64, (3,3))} \\rightarrow \\text{MP(2,2)} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\textbf{DO(prob)} \\rightarrow \\\\\n",
    "\\text{Flat} \\rightarrow \\text{L(1600, 256)} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\textbf{DO(prob)} \\rightarrow \\\\\n",
    "\\text{L(256, 128)} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\text{L(128, 10)} \\rightarrow \\text{Softmax}\n",
    "$$\n",
    "\n",
    "where \n",
    "- [`Conv`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) is a Convolution layer with the specified output channels and kernel size, with no padding and a stride of 1 by default.\n",
    "\n",
    "- [`MP`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) is the Max Pooling layer with the specified kernel size, with no padding, the stride set to the same shape as the kernel by default.\n",
    "\n",
    "- [`LReLU`](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html) is Leaky ReLU with the specified negative slope.\n",
    "\n",
    "- `Flat` is the flattening operation, which should flatten/reshape the tensor from a multi-dimensional tensor (batch_size, num_channels, width, height) into a \"flat\" tensor (batch_size, num_channels x width x height). The 2-dimensional result represents that each sample has only 1 dimension of \"flattened\" data. This has already been implemented for you\n",
    "\n",
    "- [`L`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) is a fully-connected layer with the specified input and output features.\n",
    " \n",
    "- [`DO`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) is Dropout with a dropping probability. Choose between `nn.Dropout` and `nn.Dropout2d` but __not both__ for your network.\n",
    "\n",
    "You are highly encouraged to initialise all your layers in the `__init__` method.\n",
    "\n",
    "__Reminder:__ Do not hardcode for the number of classes and the dropout probability. Use the `classes` and `drop_prob` constructor arguments instead.\n",
    "\n",
    "__Note:__ There is no need to include a Softmax layer in your neural network, as technically, [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) which we are going to use as our loss function later, already applies Softmax implicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN that uses Conv2d, MaxPool2d, and Dropout layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, classes: int, drop_prob: float = 0.5):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        classes: integer that corresponds to the number of classes for MNIST\n",
    "        drop_prob: probability of dropping a node in the neural network\n",
    "        \"\"\"\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "        \n",
    "        x = x.view(-1, 64*5*5) # Flattening – do not remove\n",
    "\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Test cases\n",
    "# Test your network's forward pass\n",
    "num_samples, num_channels, width, height = 20, 1, 28, 28\n",
    "x = torch.rand(num_samples, num_channels, width, height)\n",
    "net = DropoutCNN(10)\n",
    "y = net(x)\n",
    "print(y.shape) # torch.Size([20, 10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53c3b117",
   "metadata": {},
   "source": [
    "### Task 2.2: Training your Vanilla and Dropout CNNs\n",
    "\n",
    "Here, write down the training loop in the function `train_model` to train the CNNs you have just created. It will take in the respective NN (vanilla or dropout), as well as training and testing __data loaders__ (more on this later) that return batches of images and their respective labels to train on. \n",
    "\n",
    "Use the `torch.optim.Adam(...)` optimizer and Cross Entropy Loss `nn.CrossEntropyLoss()`.\n",
    "\n",
    "> Return the model and epoch losses.\n",
    "\n",
    "Remember to extract the loss value from the `loss` tensor by using `loss.item()`.\n",
    "\n",
    "__Tip:__ Don't be worried if your model takes a while to train. Your mileage may also vary depending on your CPU. But if you would like to speed things up, you can consider making use of your device's GPU to parallelize the matrix computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# do not remove the above line\n",
    "def train_model(loader: torch.utils.data.DataLoader, model: nn.Module):\n",
    "    \"\"\"\n",
    "    PARAMS\n",
    "    loader: the data loader used to generate training batches\n",
    "    model: the model to train\n",
    "  \n",
    "    RETURNS\n",
    "        the final trained model and losses\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \n",
    "    - create the loss and optimizer\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "    epoch_losses = []\n",
    "    for i in range(10):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for idx, data in enumerate(loader):\n",
    "            x, y = data\n",
    "            \"\"\"\n",
    "            YOUR CODE HERE\n",
    "            \n",
    "            - reset the optimizer\n",
    "            - perform forward pass\n",
    "            - compute loss\n",
    "            - perform backward pass\n",
    "            \"\"\"\n",
    "            \"\"\" YOUR CODE HERE \"\"\"\n",
    "            raise NotImplementedError\n",
    "            \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "        epoch_loss = epoch_loss / len(loader)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        print(\"Epoch: {}, Loss: {}\".format(i, epoch_loss))\n",
    "        \n",
    "\n",
    "    return model, epoch_losses\n",
    "\n",
    "print(\"======Training Vanilla Model======\")\n",
    "vanilla_model, losses = train_model(train_loader, RawCNN(10))\n",
    "print(\"======Training Dropout Model======\")\n",
    "do_model, losses = train_model(train_loader, DropoutCNN(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ecd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not remove – nothing to code here\n",
    "# run this cell before moving on\n",
    "# ensure get_accuracy from task 1.5 is defined\n",
    "\n",
    "with torch.no_grad():\n",
    "    vanilla_model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred_vanilla = vanilla_model(x)\n",
    "        acc = get_accuracy(pred_vanilla, y)\n",
    "        print(f\"vanilla acc: {acc}\")\n",
    "        \n",
    "    do_model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred_do = do_model(x)\n",
    "        acc = get_accuracy(pred_do, y)\n",
    "        print(f\"drop-out (0.5) acc: {acc}\")\n",
    "        \n",
    "\"\"\"\n",
    "The network with Dropout might under- or outperform the network without\n",
    "Dropout. However, in terms of generalisation, we are assured that the Dropout\n",
    "network will not overfit – that's the guarantee of Dropout.\n",
    "\n",
    "A very nifty trick indeed!\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32ddfda3",
   "metadata": {},
   "source": [
    "### Task 2.3: Observing Effects of Dropout\n",
    "\n",
    "Here, train your `DropoutCNN` with your `train_model(loader, model)` from Task 2.3, with `p=0.1` and `p=0.95` respectively. \n",
    "\n",
    "Explain why extreme values of Dropout don't work as well on neural networks. Look back at first principles – what does Dropout do in the first place? How does the `p` value affect how it does it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1328f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# do not remove – nothing to code here\n",
    "# run this before moving on\n",
    "\n",
    "print(\"======Training Dropout Model with Dropout Probability 0.10======\")\n",
    "do10_model, do10_losses = train_model(train_loader, DropoutCNN(10, 0.10))\n",
    "print(\"======Training Dropout Model with Dropout Probability 0.95======\")\n",
    "do95_model, do95_losses = train_model(train_loader, DropoutCNN(10, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a863f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not remove – nothing to code here\n",
    "# run this cell before moving on\n",
    "# but ensure get_accuracy from task 3.5 is defined\n",
    "\n",
    "with torch.no_grad():\n",
    "    do10_model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred_do = do10_model(x)\n",
    "        acc = get_accuracy(pred_do, y)\n",
    "        print(acc)\n",
    "\n",
    "    do95_model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred_do = do95_model(x)\n",
    "        acc = get_accuracy(pred_do, y)\n",
    "        print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41135908",
   "metadata": {},
   "source": [
    "### Concept: Sequential Model Building with PyTorch\n",
    "\n",
    "All this while, we've been adding layers one by one as attributes inside the `__init__` method. This is a natural first step as we explore what each layer does separately. But now we can speed things up!\n",
    "\n",
    "PyTorch lets you combine the declaration of multiple layers using the `nn.Sequential` API, by chaining them together in one call. It also allows you to build isolated modules that can exist on their own (either within a `nn.Module` class or otherwise) and be used as independent \"mini models\" on data tensors. Refer to https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html for more information about combining PyTorch modules to create your own.\n",
    "\n",
    "__Note:__ You should not add an array of layers inside `nn.Sequential` i.e., it's `nn.Sequential(xyz, abc, mno)`, **not** `nn.Sequential([xyz, abc, mno])`.\n",
    "\n",
    "### Demo 2.2: 3-layer Multilayer Perceptron for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcfb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = nn.Sequential(\n",
    "                nn.Linear(784, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 10),\n",
    "                nn.Softmax(1) # softmax dimension\n",
    "            )\n",
    "\n",
    "x = torch.rand(15, 784) # a batch of 15 MNIST images\n",
    "y = densenet(x) # here we simply run the sequential densenet on the `x` tensor\n",
    "print(y.shape) # a batch of 15 predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22d9a1a6",
   "metadata": {},
   "source": [
    "### Demo 2.3: 2-layer ConvNet for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9544b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = nn.Sequential(\n",
    "                nn.Conv2d(1, 32, (3,3)),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(32, 64, (3,3)),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(36864, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 10),\n",
    "                nn.Softmax(1) # softmax dimension\n",
    "            )\n",
    "\n",
    "x = torch.rand(15, 1, 28, 28) # a batch of 15 MNIST images\n",
    "y = convnet(x) # here we simply run the sequential convnet on the `x` tensor\n",
    "print (y.shape) # a batch of 15 predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3e9eaf5",
   "metadata": {},
   "source": [
    "## New dataset: CIFAR-10\n",
    "Using what you've learned with MNIST, apply the techniques to CIFAR-10, a dataset of 60K training and 10K testing images comprising of real-life objects corresponding to the following 10 classes:\n",
    "\n",
    "- airplane\t\t\t\t\t\t\t\t\t\t\n",
    "- automobile\t\t\t\t\t\t\t\t\t\t\n",
    "- bird\t\t\t\t\t\t\t\t\t\t\n",
    "- cat\t\t\t\t\t\t\t\t\t\t\n",
    "- deer\t\t\t\t\t\t\t\t\t\t\n",
    "- dog\t\t\t\t\t\t\t\t\t\t\n",
    "- frog\t\t\t\t\t\t\t\t\t\t\n",
    "- horse\t\t\t\t\t\t\t\t\t\t\n",
    "- ship\t\t\t\t\t\t\t\t\t\t\n",
    "- truck\n",
    "\n",
    "Each image is $3 \\times 32 \\times 32$, meaning we operate on 3 color channels RGB, and no longer just 1 channel (grayscale). Some example images:\n",
    "\n",
    "![PyTorch](images/cifar.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c0aab70",
   "metadata": {},
   "source": [
    "### Concept: Data Augmentation\n",
    "\n",
    "In reality, finding a well-representative, balanced dataset is difficult. To address this issue, we use __Data Augmentation__. It refers to the process of transforming data in a training dataset to generate more samples to expand the training dataset.\n",
    "\n",
    "Here, we will pick images from the original dataset `x_train`, perform some transformations $F$ on them, and append them to `x_train`. This should generate new images from the base images, containing similar features to the original images that can be learnt.\n",
    "\n",
    "Of course, the impact of data augmentation on model training depends on the types of augmentation used. Here are some common ones used:\n",
    "\n",
    "- Normalisation\n",
    "- Horizontal and Vertical Flipping\n",
    "- Rotation\n",
    "- Blurring\n",
    "- Adding noise\n",
    "- Skewing\n",
    "- Cropping (zooming in or out)\n",
    "- Brightness and Contrast\n",
    "- Shuffling pixels\n",
    "\n",
    "This results in a wide variety of new samples being created that can be used for training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d593d799",
   "metadata": {},
   "source": [
    "### The `transforms` module\n",
    "\n",
    "Here, we are going to use the `transforms` module from PyTorch to transform the images in our dataset. It contains all kinds of image transformations from `rotate` to `resize`. Check out the full list of augmentations on the PyTorch documentation: https://pytorch.org/vision/stable/transforms.html.\n",
    "\n",
    "Explore the following example to see how the transformations work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c03c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train = datasets.CIFAR10(\"./\", train=True, download=True, transform=transforms.ToTensor())\n",
    "cifar_train_loader = torch.utils.data.DataLoader(cifar_train, batch_size=128, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(cifar_train_loader))\n",
    "img = train_features[0]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,7))\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip()\n",
    "                                # YOUR CODE HERE\n",
    "                                ]) # add in your own transformations to test\n",
    "tensor_img = transform(img)\n",
    "ax1.imshow(img.permute(1,2,0))\n",
    "ax1.axis(\"off\")\n",
    "ax1.set_title(\"Before Transformation\")\n",
    "ax2.imshow(tensor_img.permute(1, 2, 0))\n",
    "ax2.axis(\"off\")\n",
    "ax2.set_title(\"After Transformation\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57de4397",
   "metadata": {},
   "source": [
    "### Task 2.4: Picking Data Augmentations\n",
    "\n",
    "Pick your favourite data augmentations! Then, you can apply them to the images from the dataset.\n",
    "\n",
    "We've already started you off with the necessary one `ToTensor()` that converts the original JPEG-format image to the PyTorch `Tensor` format. Refer to the command glossary to add your custom data augmentations from the list we've provided. \n",
    "\n",
    "**Choose at least 2 additional augmentations.** Tell us which augmentations you chose to use and why. Then tell us which augmentations you avoided and why. \n",
    "\n",
    "__Note:__ Feel free to use any augmentations you wish from the full list of augmentations shown on the [PyTorch documentation](https://pytorch.org/vision/stable/transforms.html)! There's no need to be restricted to the list that we've provided.\n",
    "\n",
    "Be creative and try different things! We recommend using trial and error to get the best performing network. Are you surprised by which transformations happen to work the best?\n",
    "\n",
    "__Note:__ Do ensure your augmentations retain the 3-dimensional shape of the CIFAR-10 images. The final images should still have the shape `(3, 32, 32)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick your data augmentations here\n",
    "def get_augmentations() -> transforms.Compose:\n",
    "    T = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "    ])\n",
    "    \n",
    "    return T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9440fb9",
   "metadata": {},
   "source": [
    "Create your data loaders that return batches of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not remove this cell\n",
    "# run this before moving on\n",
    "\n",
    "T = get_augmentations()\n",
    "\n",
    "cifar_train = datasets.CIFAR10(\"./\", train=True, download=True, transform=T)\n",
    "cifar_test = datasets.CIFAR10(\"./\", train=False, download=True, transform=T)\n",
    "\n",
    "\"\"\"\n",
    "if you feel your computer can't handle too much data, you can reduce the batch\n",
    "size to 64 or 32 accordingly, but it will make training slower. \n",
    "\n",
    "We recommend sticking to 128 but dochoose an appropriate batch size that your\n",
    "computer can manage. The training phase tends to require quite a bit of memory.\n",
    "\n",
    "CIFAR-10 images have dimensions 3x32x32, while MNIST is 1x28x28\n",
    "\"\"\"\n",
    "cifar_train_loader = torch.utils.data.DataLoader(cifar_train, batch_size=128, shuffle=True)\n",
    "cifar_test_loader = torch.utils.data.DataLoader(cifar_test, batch_size=10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3feb2b1a",
   "metadata": {},
   "source": [
    "### Task 2.5: Build a ConvNet for CIFAR-10\n",
    "\n",
    "Your task is to build a decently-sized ConvNet (i.e., $\\geq 4$ layers). Design your ConvNet with the following architecture\n",
    "\n",
    "$$\n",
    "\\text{Conv(32, (3,3))} \\rightarrow \\text{MP((2,2))} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\text{Conv(64, (3,3))} \\rightarrow \\text{MP((2,2))} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\text{GAP} \\\\ \\rightarrow \\text{L(64, 256)} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\text{L(256, 128)} \\rightarrow \\text{LReLU(0.1)} \\rightarrow \\text{L(128, 10)}\n",
    "$$\n",
    "\n",
    "where \n",
    "- [`Conv`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) is a Convolution layer with the specified output channels and kernel size\n",
    "\n",
    "- [`MP`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) is the Max Pooling layer with the specified kernel size\n",
    "\n",
    "- [`LReLU`](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html) is Leaky ReLU with the specified negative slope\n",
    "\n",
    "- `GAP` is the Global Average Pooling operation (already implemented for you)\n",
    "\n",
    "- [`L`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) is a fully-connected layer with the specified input and output features\n",
    "\n",
    "---\n",
    "\n",
    "You must use the [`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) API to build two parts:\n",
    "1. The `self.conv` attribute must contain all the Convolutional, Pooling, and Activation layers\n",
    "2. The `self.fc` attribute must contain all the fully-connected layers after the flattening\n",
    "\n",
    "The `self.conv` and `self.fc` attributes are already given to you. All you need to do is chain the arbitrary `nn.XYZ` layers together based on the architecture stated above.\n",
    "\n",
    "__Note:__ The flattening is already done for you via Global Average Pooling (GAP) in the `forward` method. Do not add the Softmax activation in the `self.fc` Sequential module.\n",
    "\n",
    "__Reminder:__ Do not hardcode for the number of classes. Use the `classes` argument instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46bd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARCNN(nn.Module):\n",
    "    def __init__(self, classes: int):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        classes: integer that corresponds to the number of classes for CIFAR-10\n",
    "        \"\"\"\n",
    "        self.conv = nn.Sequential(\n",
    "                        \"\"\" YOUR CODE HERE \"\"\"\n",
    "                        raise NotImplementedError\n",
    "                        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "                    )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "                        \"\"\" YOUR CODE HERE \"\"\"\n",
    "                        raise NotImplementedError\n",
    "                        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "                    )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "        x = x.view(x.shape[0], 64, 6*6).mean(2) # GAP – do not remove this line\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edd7fc3a",
   "metadata": {},
   "source": [
    "### Train your ConvNet on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f36e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# do not remove – nothing to code here\n",
    "# run this cell before moving on\n",
    "\n",
    "cifar10_model, losses = train_model(cifar_train_loader, CIFARCNN(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6e68deb",
   "metadata": {},
   "source": [
    "### Test the CIFAR-10 ConvNet model using the testing data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not remove – nothing to code here\n",
    "# run this cell before moving on\n",
    "# but ensure get_accuracy from task 3.5 is defined\n",
    "\n",
    "with torch.no_grad():\n",
    "    cifar10_model.eval()\n",
    "    for i, data in enumerate(cifar_test_loader):\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = cifar10_model(x)\n",
    "        acc = get_accuracy(pred, y)\n",
    "        print(f\"cifar accuracy: {acc}\")\n",
    "        \n",
    "# don't worry if the CIFAR-10 accuracy is low, it's a tough dataset to crack.\n",
    "# as long as you get something shy of 50%, you should be alright!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "487b86e8",
   "metadata": {},
   "source": [
    "## 3 - Recurrent Neural Networks (RNNs)\n",
    "In this part, we'll explore how an RNN works, and create a simple RNN model to predict values of a sine wave based on prior inputs.\n",
    "\n",
    "### Packages\n",
    "The necessary packages are imported in the cell below. Please make sure that you run this cell before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(2109)\n",
    "np.random.seed(2109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3e349a8",
   "metadata": {},
   "source": [
    "\n",
    "### Concept: Memory\n",
    "\n",
    "Traditional models like MLPs or CNNs see each input on its own—they have no memory of what came before. An RNN, on the other hand, is built to handle sequences. It keeps a \"memory\" of past information through a hidden state, allowing it to make predictions that depend on earlier steps in the sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86a6d376",
   "metadata": {},
   "source": [
    "### Demo 3.1 - RNN Cell\n",
    "<center><img src=\"images/rnn_superscript_updated.png\" style=\"width:800px\"></center>\n",
    "\n",
    "At the core of the RNN is the RNN cell, which processes one time step of the sequence at a time. For each time step, the cell updates its hidden state based on the current input and the previous hidden state.\n",
    "\n",
    "We first implement the computations for a single time step. The diagram below describes the operations for a single time step of an RNN cell.\n",
    "<center><img src=\"images/rnn_cell_superscript_updated.png\" style=\"width:800px\"></center>\n",
    "\n",
    "__Note__: an RNN cell outputs the hidden state $h^{[t]}$, but the function that you'll implement `rnn_cell_forward`, also calculates the prediction $\\hat{y}^{[t]}$. Keep in mind that the activation functions within the RNN cell can be replaced with other activation functions. This implementation uses tanh and softmax but they can be replaced by other activation functions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fdcf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_cell_forward(xt, h_prev, Wxh, Whh, Why, bh, by):\n",
    "    \"\"\"\n",
    "    Implements a single forward step of the RNN-cell\n",
    "\n",
    "    Args:\n",
    "        xt: 2D tensor of shape (nx, m)\n",
    "            Input data at timestep \"t\"\n",
    "        h_prev: 2D tensor of shape (nh, m)\n",
    "            Hidden state at timestep \"t-1\"\n",
    "        Wxh: 2D tensor of shape (nx, nh)\n",
    "            Weight matrix multiplying the input\n",
    "        Whh: 2D tensor of shape (nh, nh)\n",
    "            Weight matrix multiplying the hidden state\n",
    "        Why: 2D tensor of shape (nh, ny)\n",
    "            Weight matrix relating the hidden-state to the output\n",
    "        bh: 1D tensor of shape (nh, 1)\n",
    "            Bias relating to next hidden-state\n",
    "        by: 2D tensor of shape (ny, 1)\n",
    "            Bias relating the hidden-state to the output\n",
    "\n",
    "    Returns:\n",
    "        yt_pred -- prediction at timestep \"t\", tensor of shape (ny, m)\n",
    "        h_next -- next hidden state, of shape (nh, m)\n",
    "    \"\"\"\n",
    "    h_next = torch.tanh(Whh.T @ h_prev + Wxh.T @ xt + bh)\n",
    "    yt_pred = F.softmax(Why.T @ h_next + by, dim=0)\n",
    "    return yt_pred, h_next"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16aaf900",
   "metadata": {},
   "source": [
    "### Demo 3.2 - Generate Sine Wave Data\n",
    "\n",
    "We'll use `torch.linspace(start, end, steps)` to create a sequence of evenly spaced values between 0 and $8\\pi$ over `num_time_steps` intervals. This will serve as the x-values (time points) for the sine wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a97e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_sine_wave(num_time_steps):\n",
    "    \"\"\"\n",
    "    Generates a sine wave data\n",
    "\n",
    "    Args:\n",
    "        num_time_steps: int\n",
    "            Number of time steps\n",
    "    Returns:\n",
    "        data: 1D tensor of shape (num_time_steps,)\n",
    "            Sine wave data with corresponding time steps\n",
    "    \"\"\"\n",
    "    x = torch.linspace(0, 8*torch.pi, num_time_steps)\n",
    "    data = torch.sin(x)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_time_steps = 500\n",
    "sine_wave_data = generate_sine_wave(num_time_steps)\n",
    "\n",
    "# Plot the sine wave\n",
    "plt.plot(sine_wave_data)\n",
    "plt.title('Sine Wave')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aafe13e",
   "metadata": {},
   "source": [
    "### Demo 3.3 Create sequences\n",
    "\n",
    "When training RNNs, it's common to divide time series data into overlapping windows. The label used for comparison is the next value in the sequence.\n",
    "\n",
    "For example if we have series of $n$ data points and a window size of 3, the input sequences are $[x^{[1]}, x^{[2]}, x^{[3]}]$ to predict $x^{[4]}$, $[x^{[2]}, x^{[3]}, x^{[4]}]$ to predict $x^{[5]}$, $[x^{[3]}, x^{[4]}, x^{[5]}]$, to predict $x^{[6]}$, and so on.\n",
    "\n",
    "Below is our implementation of `create_sequences` which generates sequences and their corresponding labels from a given sine wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(sine_wave, seq_length):\n",
    "    \"\"\"\n",
    "    Create overlapping sequences from the input time series and generate labels \n",
    "    Each label is the value immediately following the corresponding sequence.\n",
    "    \n",
    "    Args:\n",
    "        sine_wave: A 1D tensor representing the time series data (e.g., sine wave).\n",
    "        seq_length: int. The length of each sequence (window) to be used as input to the RNN.\n",
    "\n",
    "    Returns: \n",
    "        windows: 2D tensor where each row is a sequence (window) of length `seq_length`.\n",
    "        labels: 1D tensor where each element is the next value following each window.\n",
    "    \"\"\"\n",
    "    windows = sine_wave.unfold(0, seq_length, 1)\n",
    "    labels = sine_wave[seq_length:]\n",
    "    return windows[:-1], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e9198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences and labels\n",
    "seq_length = 20\n",
    "sequences, labels = create_sequences(sine_wave_data, seq_length)\n",
    "# Add extra dimension to match RNN input shape [batch_size, seq_length, num_features]\n",
    "sequences = sequences.unsqueeze(-1)\n",
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed35f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the sequences into training data (first 80%) and test data (remaining 20%) \n",
    "train_size = int(len(sequences) * 0.8)\n",
    "train_seqs, train_labels = sequences[:train_size], labels[:train_size]\n",
    "test_seqs, test_labels = sequences[train_size:], labels[train_size:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ad1b640",
   "metadata": {},
   "source": [
    "### Task 3.1: Building RNN Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23790704",
   "metadata": {},
   "source": [
    "Now we're ready to build the RNN, following the architecture:\n",
    "$$x \\rightarrow \\text{RNN} \\rightarrow \\text{Linear}(1)$$\n",
    "\n",
    "- [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html): a basic recurrent layer in PyTorch. It takes an input of sequences and returns output for each time step, and the hidden state of the last time step. The `hidden_size` determines the number of hidden units in the RNN.\n",
    " \n",
    "- [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html): fully connected layer. The output from the RNN's last hidden state will be passed through this layer to predict a single value (the next time step in the series)\n",
    "\n",
    "We'll do so by defining the `__init__` and `forward` functions in our `SineRNN` class, which inherits from `nn.Module`.\n",
    "\n",
    "__Note:__ For all your networks hereon, the only constructor argument is `classes`. Do not add any other parameters to the `__init__` method. Remember not to hardcode and use the `classes` argument instead. For RNN layer, use `batch_first=True` to ensure that the batch dimension is handled as the first input dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Initialize the SineRNN model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The number of input features per time step (typically 1 for univariate time series).\n",
    "            hidden_size (int): The number of units in the RNN's hidden layer.\n",
    "            output_size (int): The size of the output (usually 1 for predicting a single value).\n",
    "        \"\"\"\n",
    "        super(SineRNN, self).__init__()\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25110f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "input_size = output_size = 1\n",
    "hidden_size = 50\n",
    "model = SineRNN(input_size, hidden_size, output_size).to(device)\n",
    "assert [layer.detach().numpy().shape for _, layer in model.named_parameters()]\\\n",
    "      == [(50, 1), (50, 50), (50,), (50,), (1, 50), (1,)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1775af81",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ba89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(train_seqs)\n",
    "    loss = criterion(outputs.squeeze(), train_labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27a67379",
   "metadata": {},
   "source": [
    "### Evaluating\n",
    "\n",
    "Once training is complete, we can evaluate the model by plotting its predictions against the actual sine wave. We use a portion of test data that the model hasn't seen during training to check how well it generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on unseen data\n",
    "model.eval()\n",
    "y_pred = []\n",
    "input_seq = test_seqs[0]  # Start with the first testing sequence\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(len(test_seqs)):\n",
    "        output = model(input_seq)\n",
    "        y_pred.append(output.item())\n",
    "\n",
    "        # Use the predicted value as the next input sequence\n",
    "        next_seq = torch.cat((input_seq[1:, :], output.unsqueeze(0)), dim=0)\n",
    "        input_seq = next_seq\n",
    "\n",
    "# Plot the true sine wave and predictions\n",
    "plt.plot(sine_wave_data, c='gray', label='Actual data')\n",
    "plt.scatter(np.arange(seq_length + len(train_labels)), sine_wave_data[:seq_length + len(train_labels)], marker='.', label='Train')\n",
    "x_axis_pred = np.arange(len(sine_wave_data) - len(test_labels), len(sine_wave_data))\n",
    "plt.scatter(x_axis_pred, y_pred, marker='.', label='Predicted')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba44440",
   "metadata": {},
   "source": [
    "### Demo 3.4: Appending Noise to Sequences\n",
    "\n",
    "In real-world data, sequences often contain noise or fluctuations that can make predictions more challenging. To simulate this, we can append random noise to our sine wave sequences.\n",
    "\n",
    "In this demo, we will append a sequence of noises to the sine wave sequences. The model has to learn to predict the sine wave despite the added noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b467171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_with_noise(sine_wave, sine_wave_length, noise_length):\n",
    "    \"\"\"\n",
    "    Create overlapping sequences from the input time series and generate labels.\n",
    "    Each label is the value immediately following the corresponding sequence.\n",
    "    Additionally, noise of the specified length is appended to the sequences.\n",
    "\n",
    "    Args:\n",
    "        sine_wave: A 1D tensor representing the time series data (e.g., sine wave).\n",
    "        sine_wave_length: int. The length of the sine wave window.\n",
    "        noise_length: int. The length of noise to be appended to each sequence.\n",
    "\n",
    "    Returns:\n",
    "        windows: 2D tensor where each row is a sequence of length `sine_wave_length + noise_length`.\n",
    "        labels: 1D tensor where each element is the next value following each window.\n",
    "    \"\"\"\n",
    "    windows = sine_wave.unfold(0, sine_wave_length, 1)\n",
    "    labels = sine_wave[sine_wave_length:]\n",
    "    noise = torch.randn(windows.shape[0], noise_length)\n",
    "    windows = torch.cat((windows, noise), dim=1)\n",
    "    return windows[:-1], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences and labels\n",
    "sine_wave_length = 20\n",
    "noise_length = 20\n",
    "sequences, labels = create_sequences_with_noise(sine_wave_data, sine_wave_length, noise_length)\n",
    "# Add extra dimension to match RNN input shape [batch_size, seq_length, num_features]\n",
    "sequences = sequences.unsqueeze(-1)\n",
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ccc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the sequences into training data (first 80%) and test data (remaining 20%) \n",
    "train_size = int(len(sequences) * 0.8)\n",
    "train_seqs, train_labels = sequences[:train_size], labels[:train_size]\n",
    "test_seqs, test_labels = sequences[train_size:], labels[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194cef6",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5eeda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "input_size = output_size = 1\n",
    "hidden_size = 50\n",
    "model = SineRNN(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# Define loss function, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(train_seqs)\n",
    "    loss = criterion(outputs.squeeze(), train_labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1f460",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(test_seqs).squeeze()\n",
    "    y_true = test_labels.squeeze()\n",
    "\n",
    "print(\"Test loss:\", criterion(y_pred, y_true))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(y_true[1::2].numpy(), label=\"True value\", color='black')\n",
    "plt.plot(y_pred[1::2].numpy(), '--', label=\"Predicted value\", color='red')\n",
    "plt.title(\"SineRNN Predictions\")\n",
    "plt.xlabel(\"Test sequence index\")\n",
    "plt.ylabel(\"Target value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed16fc",
   "metadata": {},
   "source": [
    "As we increase the length of the noise appended to the sequence, it gets harder and harder for the RNN to predict the sine wave accurately.\n",
    "\n",
    "Note that RNNs processes the data sequentially, so RNNs often face difficulties retaining information over long sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f6ec20",
   "metadata": {},
   "source": [
    "# 4 Attention Mechanism and Transformers\n",
    "\n",
    "In this task, you will train a transformer model to see if it can overcome these limitations. The transformer model will use the architecture provided below.\n",
    "\n",
    "![](images/transformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ddc6d",
   "metadata": {},
   "source": [
    "## Task 4.1: Positional Encoding Layer\n",
    "\n",
    "Positional encoding explicitly injects positional information into the inputs. We use the positional encoding scheme discussed in lecture, reproduced as follows:\n",
    "\n",
    "$$\n",
    "PE{(i, 2k)} = \\sin\\left(\\dfrac{i}{10000^{2k/d}}\\right) \\\\\n",
    "PE{(i, 2k+1)} = \\cos\\left(\\dfrac{i}{10000^{2k/d}}\\right)\n",
    "$$\n",
    "\n",
    "where $d$ is the model's hidden dimension.\n",
    "\n",
    "Implement the `PositionalEncoding` class, which extends from `nn.Module`, that generates positional encodings for input sequences. **In your implementation, you may assume that `hidden_size` is even.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self):\n",
    "        # You do not need to change anything in this function.\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Adds positional encoding to the input tensor.\n",
    "\n",
    "        You should use vectorized operations to compute the positional encoding.\n",
    "        The use of Python loops is not allowed.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, hidden_size)\n",
    "        \"\"\"\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "encoder = PositionalEncoding()\n",
    "x0 = torch.zeros((1, 2, 4))\n",
    "y0 = encoder(x0)\n",
    "a0 = torch.tensor([[[0.0000, 1.0000, 0.0000, 1.0000],\n",
    "                    [0.8415, 0.5403, 0.0100, 0.9999]]])\n",
    "assert torch.allclose(y0, a0, atol=1e-4)\n",
    "\n",
    "x1 = torch.ones((1, 4, 6))\n",
    "y1 = encoder(x1)\n",
    "a1 = torch.tensor([[[1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 2.0000],\n",
    "                    [1.8415, 1.5403, 1.0464, 1.9989, 1.0022, 2.0000],\n",
    "                    [1.9093, 0.5839, 1.0927, 1.9957, 1.0043, 2.0000],\n",
    "                    [1.1411, 0.0100, 1.1388, 1.9903, 1.0065, 2.0000]]])\n",
    "assert torch.allclose(y1, a1, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1d5d3",
   "metadata": {},
   "source": [
    "## Demo 4.1: The Transformer Model\n",
    "\n",
    "Here, we will implement the model architecture for the transformer model using PyTorch. The transformer model consists of a single encoder layer with a specified hidden dimension in the feed-forward network.\n",
    "\n",
    "A layer in the transformer model is defined using `nn.TransformerEncoderLayer`, with the following minimal usage:\n",
    "\n",
    "```python\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=2048, batch_first=False)\n",
    "```\n",
    "- `d_model` is the hidden dimension of the model.\n",
    "- `nhead` is the number of attention heads. Each attention head is an independent self-attention mechanism that could possibly learn different aspects of the input sequence. In this transformer model, we will set `nhead=1` to implement only one self-attention mechanism.\n",
    "- `dim_feedforward` is the hidden dimension of the feed-forward network.\n",
    "- `batch_first=True` ensures that the input and output tensors are of shape `(batch_size, seq_length, hidden_dim)`, which is convenient for our implementation.\n",
    "\n",
    "\n",
    "The transformer encoder is then defined using `nn.TransformerEncoder`, which takes the encoder layer and the number of layers as arguments:\n",
    "\n",
    "```python\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "```\n",
    "- `num_layers=1` specifies that we will use only one encoder layer.\n",
    "\n",
    "There are other optional parameters that can be set, you may refer to the [PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c19c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Initializes the TransformerNN model. We use the same hidden size for the feedforward network and the Transformer encoder.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The number of input features per time step (typically 1 for univariate time series).\n",
    "            hidden_size (int): The number of units in the Transformer's hidden layers.\n",
    "            output_size (int): The size of the output (usually 1 for predicting a single value).\n",
    "        \"\"\"\n",
    "        super(TransformerNN, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.positional_encoder = PositionalEncoding()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, dim_feedforward=hidden_size, nhead=1, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # The encoder outputs a sequence of hidden states, so\n",
    "        # we take the mean across the sequence length dimension.\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        out = self.fc_out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac7a6d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerNN(input_size=1, hidden_size=50, output_size=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bf345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_seqs)\n",
    "    loss = criterion(outputs.squeeze(), train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d461d3",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cba2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(test_seqs).squeeze()\n",
    "    y_true = test_labels.squeeze()\n",
    "\n",
    "print(\"Test loss:\", criterion(y_pred, y_true))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(y_true[1::2].numpy(), label=\"True value\", color='black')\n",
    "plt.plot(y_pred[1::2].numpy(), '--', label=\"Predicted value\", color='red')\n",
    "plt.title(\"TransformerNN Predictions\")\n",
    "plt.xlabel(\"Test sequence index\")\n",
    "plt.ylabel(\"Target value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b9813",
   "metadata": {},
   "source": [
    "## Task 4.2: Visualizing Attention Scores\n",
    "\n",
    "We can visualize the attention scores from the transformer model to understand which parts of the input sequence the model focuses on when making predictions.\n",
    "\n",
    "Here are 3 different plots of attention scores, one of which is actually taken from the self-attention layer of our trained transformer model. Which of the 3 plots **most likely** corresponds to the attention scores from our trained transformer model? Explain your reasoning.\n",
    "\n",
    "**Plot A**\n",
    "\n",
    "![](images/attention_A.png)\n",
    "\n",
    "**Plot B**\n",
    "\n",
    "![](images/attention_B.png)\n",
    "\n",
    "**Plot C**\n",
    "\n",
    "![](images/attention_C.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11699d8b",
   "metadata": {},
   "source": [
    "## Task 4.3: Comparing Transformers with or without Positional Encoding\n",
    "\n",
    "Currently, the transformer model makes use of the positional encoding layer. Train another transformer model **without the positional encoding layer** on the same dataset and evaluate its performance.\n",
    "\n",
    "Attach the plots of both models on Coursemology. Discuss the differences in performance between the two models and explain why positional encoding is important for transformer models when dealing with sequential data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may use this cell and create new cells to experiment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b585b00",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Once you are done, please submit your work to Coursemology, by copying the right snippets of code into the corresponding box that says \"Your answer,\"and click \"Save.\" After you save, you can still make changes to your submission.\n",
    "\n",
    "Once you are satisfied with what you have uploaded, click \"Finalize submission.\" Note that once your submission is finalized, it is considered to be submitted for grading and cannot be changed. If you need to undo this action, you will have to email your assigned tutor for help. Please do not finalize your submission until you are sure that you want to submit your solutions for grading.\n",
    "\n",
    "*Have fun and enjoy coding.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
